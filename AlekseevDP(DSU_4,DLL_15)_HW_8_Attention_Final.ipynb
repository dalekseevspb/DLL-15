{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wFFQrcT-b3sl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## AlekseevDP(DSU-4,DLL-15)_HW#8_Внимание.\n",
        "\n",
        "Задание:\n",
        "- Возьмите англо-русскую пару фраз (https://www.manythings.org/anki/)\n",
        "\n",
        "- Обучите на них seq2seq with attention:\n",
        "  - На основе MLP \n",
        "  - На основе скалярного произведения\n",
        "  \n",
        "- Оцените качество\n"
      ],
      "metadata": {
        "id": "qs43GIpSCdMA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l72U8N4ZCbyu"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING = \"1\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCzxVlyEG_WE",
        "outputId": "d14a1c24-bbcc-41f8-ab9a-67dc844a631b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://www.manythings.org/anki/rus-eng.zip\n",
        "# !unzip rus-eng.zip"
      ],
      "metadata": {
        "id": "ByZwfI0JG_T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Файл https://www.manythings.org/anki/rus-eng.zip потребовал предобработки в программе Anki, а именно - удаления колонки со служебной информацией (номер  карточки перевода, автор и т.п.), иначе при загрузке корпуса возникала ошибка. Предобработанный файл: eng-rus_prepared_full.txt (для быстрого примера см. в репозитории Github файл 'eng-rus_prepared_example.txt')"
      ],
      "metadata": {
        "id": "KXhRJh3Ohr8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# переместим предобработанный файл в каталог '/data' и переименуем в 'eng-rus.txt'\n",
        "!mkdir '/content/data'\n",
        "# !mv eng-rus_prepared_example.txt '/content/data/eng-rus.txt'\n",
        "!mv eng-rus_prepared_full.txt '/content/data/eng-rus.txt'"
      ],
      "metadata": {
        "id": "tTv86giCG_Q7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -50 data/eng-rus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0easvWv5HxSv",
        "outputId": "6bbdde77-b7cb-4102-cc2f-3a53d1152615"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tМарш!\n",
            "Hi.\tЗдравствуйте.\n",
            "Run!\tБеги!\n",
            "Run.\tБеги!\n",
            "Who?\tКто?\n",
            "Wow!\tВот это да!\n",
            "Duck!\tПригнись!\n",
            "Fire!\tОгонь!\n",
            "Help!\tПомогите!\n",
            "Hide.\tПрячься.\n",
            "Jump!\tПрыгай!\n",
            "Jump.\tПрыгай!\n",
            "Stay.\tОставайся.\n",
            "Stop!\tСтой!\n",
            "Wait!\tПодожди!\n",
            "Wait.\tЖдите.\n",
            "Do it.\tСделай это.\n",
            "Go on.\tПродолжай.\n",
            "Hello!\tЗдравствуйте.\n",
            "Hurry!\tПоспешите.\n",
            "I ran.\tЯ бежал.\n",
            "I see.\tПонимаю.\n",
            "I try.\tЯ пытаюсь.\n",
            "I won!\tЯ победил!\n",
            "Oh no!\tО нет!\n",
            "Relax.\tРасслабьтесь.\n",
            "Shoot!\tСтреляй!\n",
            "Smile.\tУлыбочка.\n",
            "Sorry?\tИзвините?\n",
            "Attack!\tВ атаку!\n",
            "Buy it.\tКупите её.\n",
            "Cheers!\tЗа ваше здоровье!\n",
            "Eat it.\tСъешь это.\n",
            "Eat up.\tДоедай.\n",
            "Freeze!\tНи с места!\n",
            "Get up.\tВставай.\n",
            "Go now.\tА теперь уходи.\n",
            "Got it!\tПонял!\n",
            "Got it?\tПонял?\n",
            "He ran.\tОн бежал.\n",
            "Hop in.\tЗалезай.\n",
            "Hug me.\tОбними меня.\n",
            "I fell.\tЯ упал.\n",
            "I knit.\tЯ вяжу.\n",
            "I know.\tЯ знаю.\n",
            "I left.\tЯ ушёл.\n",
            "I lied.\tЯ солгал.\n",
            "I lost.\tЯ проиграл.\n",
            "I paid.\tЯ заплатил.\n",
            "I pass.\tЯ пас.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "CmMLUnBhHxPy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Через библиотеку Unicodedata не удалось \"забороть\" кодировку предложений на русском языке, хотя кодировка UTF-8 включает в себя в т.ч. русские буквы (ошибка не возникала, но русскоязычная часть корпуса получалась всегда пустой - 0 фраз). Поэтому нашел альтернативный вариант - русские фразы переводить в транслит с использованием другой библиотеки (Unidecode):"
      ],
      "metadata": {
        "id": "-Zw-0lHtV7ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RROLiYaiHxIz",
        "outputId": "aadd52db-a3cf-4478-f268-c1a67f06f519"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 28.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unidecode import unidecode"
      ],
      "metadata": {
        "id": "e9uAxoTkJ6st"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        # c for c in unicodedata.normalize('NFD', s)  # Turn a Unicode string to plain ASCII, \n",
        "        # if unicodedata.category(c) != 'Mn'          # thanks to http://stackoverflow.com/a/518232/2809427\n",
        "        c for c in unidecode(s)\n",
        ")\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "2HoEh5pGJ6pk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "fJLaQRMpLTyw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## На \"типовых\" префиксах начала предложений (из туториала/лекции) модель Seq2seq показывала хорошую точность предсказаний (лосс ниже 1.0), т.к. корпус был небольшой и предложения короткие. Поэтому с целью эксперимента задача была усложнена: увеличена длина предложения до 100 символов, а также добавлены новые префиксы начала предложений. Итоговый корпус для обучения модели составил 29743 фразы (см.ниже)."
      ],
      "metadata": {
        "id": "y5XjTYr3jI2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 100\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am\", \"i m\",\n",
        "    \"he is\", \"he s\",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re\",\n",
        "    \"we are\", \"we re\",\n",
        "    \"they are\", \"they re\",\n",
        "    \"i can\", \"i can t\",\n",
        "    \"that is\", \"that s\",\n",
        "    \"we will\", \"we ll\",\n",
        "    \"i was\", \"he was\", \"she was\",\n",
        "    \"do you\", \"are you\",\n",
        "    \"i have\", \"i ve\", \"i had\", \"i d\",\n",
        "    \"what is\", \"what s\", \"what was\",\n",
        "    \"what do\", \"what did\",\n",
        "    \"we have\", \"we ve\",\n",
        "    \"i do\", \"i don t\",\n",
        "    \"did\", \"i ll\",\n",
        "    \"there is\", \"there s\",\n",
        "    \"how\", \"when\"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "pbAbIeN7LTq4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31ZdhRzPJ6mc",
        "outputId": "be58ff8e-28da-4e62-cd92-097126a2d7dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 746410 sentence pairs\n",
            "Trimmed to 29743 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 13446\n",
            "eng 6084\n",
            "['u menia est neskol ko dollarov .', 'i have a few dollars .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfc_KqarMn13",
        "outputId": "1132f902-c9c6-4638-ee76-ad8a7bc4edc3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['skol ko stoit etot galstuk ?', 'how much does this tie cost ?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Реализация 'seq2seq with attention' на основе MLP (Multilayer Perceptron)"
      ],
      "metadata": {
        "id": "wFFQrcT-b3sl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgtWqznCM9uH"
      },
      "source": [
        "The Encoder\n",
        "-----------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "ObuftFZIG_KV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwLTlgSyM9uK"
      },
      "source": [
        "The Decoder\n",
        "-----------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "TcSfydjGOnFz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "ZdFwSHt6Oma5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "Elj7K0RRO6GO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "FEsgDgKaO6DL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    # plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    # plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        # plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        # if iter % plot_every == 0:\n",
        "        #     plot_loss_avg = plot_loss_total / plot_every\n",
        "        #     plot_losses.append(plot_loss_avg)\n",
        "        #     plot_loss_total = 0\n",
        "\n",
        "    return "
      ],
      "metadata": {
        "id": "_3Xqv2VoPJZ0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "metadata": {
        "id": "WUfpVDrcOmXx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "BkrGr-8pPfc3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 150000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAaRiXpAPjUL",
        "outputId": "4120cc65-756e-4419-b38a-aa71307f65bd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 24s (- 40m 44s) (5000 3%) 3.7567\n",
            "2m 41s (- 37m 44s) (10000 6%) 3.2135\n",
            "4m 2s (- 36m 19s) (15000 10%) 2.9123\n",
            "5m 20s (- 34m 46s) (20000 13%) 2.7284\n",
            "6m 40s (- 33m 21s) (25000 16%) 2.5825\n",
            "7m 59s (- 31m 59s) (30000 20%) 2.4494\n",
            "9m 22s (- 30m 46s) (35000 23%) 2.3253\n",
            "10m 41s (- 29m 25s) (40000 26%) 2.2421\n",
            "12m 1s (- 28m 3s) (45000 30%) 2.1619\n",
            "13m 23s (- 26m 46s) (50000 33%) 2.1157\n",
            "14m 43s (- 25m 26s) (55000 36%) 2.0680\n",
            "16m 3s (- 24m 5s) (60000 40%) 1.9918\n",
            "17m 25s (- 22m 47s) (65000 43%) 1.9160\n",
            "18m 45s (- 21m 26s) (70000 46%) 1.8715\n",
            "20m 5s (- 20m 5s) (75000 50%) 1.7909\n",
            "21m 27s (- 18m 46s) (80000 53%) 1.7812\n",
            "22m 47s (- 17m 26s) (85000 56%) 1.7462\n",
            "24m 7s (- 16m 5s) (90000 60%) 1.7342\n",
            "25m 29s (- 14m 45s) (95000 63%) 1.7131\n",
            "26m 49s (- 13m 24s) (100000 66%) 1.6164\n",
            "28m 9s (- 12m 4s) (105000 70%) 1.6231\n",
            "29m 30s (- 10m 43s) (110000 73%) 1.6046\n",
            "30m 49s (- 9m 22s) (115000 76%) 1.5407\n",
            "32m 8s (- 8m 2s) (120000 80%) 1.5268\n",
            "33m 28s (- 6m 41s) (125000 83%) 1.5211\n",
            "34m 47s (- 5m 21s) (130000 86%) 1.5052\n",
            "36m 6s (- 4m 0s) (135000 90%) 1.5122\n",
            "37m 26s (- 2m 40s) (140000 93%) 1.4661\n",
            "38m 44s (- 1m 20s) (145000 96%) 1.4312\n",
            "40m 2s (- 0m 0s) (150000 100%) 1.4061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9b4NQtzPjQp",
        "outputId": "68a40cca-bca9-4577-a162-d6324239fcb7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> podobnaia lest ni k chemu ne privediot .\n",
            "= that sort of flattery will get you nowhere .\n",
            "< that seems to make sure . <EOS>\n",
            "\n",
            "> mne prishlos ostat sia doma .\n",
            "= i had to stay home .\n",
            "< i had to stay home . <EOS>\n",
            "\n",
            "> chto ty sdelal s moimi ochkami ? minutu nazad oni byli zdes .\n",
            "= what did you do with my glasses ? they were here a minute ago .\n",
            "< what they they here you were doing with him with him here . <EOS>\n",
            "\n",
            "> kak dolgo ia spal ?\n",
            "= how long did i sleep ?\n",
            "< how long did i sleep ? <EOS>\n",
            "\n",
            "> kak ty etogo dobilsia ?\n",
            "= how did you pull that off ?\n",
            "< how did you get that ? <EOS>\n",
            "\n",
            "> on krasivyi .\n",
            "= he is handsome .\n",
            "< he is handsome . <EOS>\n",
            "\n",
            "> dumaesh tom pokhudel ?\n",
            "= do you think tom has lost weight ?\n",
            "< do you think tom is a ? <EOS>\n",
            "\n",
            "> ia reshil vypolnit rabotu nezavisimo ot togo kak tiazhelo eto moglo by byt .\n",
            "= i made up my mind to do the work no matter how hard it might be .\n",
            "< i made up to buy a job to buy up it it to to to . <EOS>\n",
            "\n",
            "> chego ty na samom dele khochesh ?\n",
            "= what do you really want ?\n",
            "< what do really really want ? <EOS>\n",
            "\n",
            "> tom tebe rasskazal ?\n",
            "= did tom tell you ?\n",
            "< did tom tell you ? <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Реализация 'seq2seq with attention' на основе скалярного произведения (Dot Product Attention). Адаптировано с использованием туториала: https://github.com/spro/practical-pytorch/blob/c520c52e68e945d88fff563dba1c028b6ec0197b/seq2seq-translation/seq2seq-translation.ipynb"
      ],
      "metadata": {
        "id": "Eq_dWhXk0yfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "cxUKr_5C8mDi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "USE_CUDA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7s51kJX7pzN",
        "outputId": "53443bdd-a2df-4e1a-ca06-284013f41574"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dktEz6uS2EV",
        "outputId": "04bd6754-5d3a-453b-9936-0eb26dfc838d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 24 20:19:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0    30W /  70W |   1264MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKYd1Vg2arIu"
      },
      "source": [
        "## Turning training data into Tensors/Variables\n",
        "\n",
        "To train we need to turn the sentences into something the neural network can understand, which of course means numbers. Each sentence will be split into words and turned into a Tensor, where each word is replaced with the index (from the Lang indexes made earlier). While creating these tensors we will also append the EOS token to signal that the sentence is over.\n",
        "\n",
        "![](https://i.imgur.com/LzocpGH.png)\n",
        "\n",
        "A Tensor is a multi-dimensional array of numbers, defined with some type e.g. FloatTensor or LongTensor. In this case we'll be using LongTensor to represent an array of integer indexes.\n",
        "\n",
        "Trainable PyTorch modules take Variables as input, rather than plain Tensors. A Variable is basically a Tensor that is able to keep track of the graph state, which is what makes autograd (automatic calculation of backwards gradients) possible."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Return a list of indexes, one for each word in the sentence\n",
        "def indexes_from_sentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def variable_from_sentence(lang, sentence):\n",
        "    indexes = indexes_from_sentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
        "\n",
        "    if USE_CUDA: var = var.cuda()\n",
        "    return var\n",
        "\n",
        "def variables_from_pair(pair):\n",
        "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
        "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
        "    return (input_variable, target_variable)"
      ],
      "metadata": {
        "id": "U39_Jws_8Sk_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxQG8CdAarIw"
      },
      "source": [
        "# Building the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfkOAfERarIw"
      },
      "source": [
        "## The Encoder\n",
        "\n",
        "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "        \n",
        "    def forward(self, word_inputs, hidden):\n",
        "        # Note: we run this all at once (over the whole input sequence)\n",
        "        seq_len = len(word_inputs)\n",
        "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
        "        if USE_CUDA: hidden = hidden.cuda()\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "NSFfxsru8blZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPZH_kCmarIy"
      },
      "source": [
        "## Attention Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL9tqad8arI1"
      },
      "source": [
        "### Interpreting the Luong et al. model(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcuejxRBarI1"
      },
      "source": [
        "[Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025) by Luong et al. describe a few more attention models that offer improvements and simplifications. They describe a few \"global attention\" models, the distinction between them being the way the attention scores are calculated.\n",
        "\n",
        "The general form of the attention calculation relies on the target (decoder) side hidden state and corresponding source (encoder) side state, normalized over all states to get values summing to 1:\n",
        "\n",
        "$$\n",
        "a_t(s) = align(h_t, \\bar h_s)  = \\dfrac{exp(score(h_t, \\bar h_s))}{\\sum_{s'} exp(score(h_t, \\bar h_{s'}))}\n",
        "$$\n",
        "\n",
        "The specific \"score\" function that compares two states is either *dot*, a simple dot product between the states; *general*, a a dot product between the decoder hidden state and a linear transform of the encoder state; or *concat*, a dot product between a new parameter $v_a$ and a linear transform of the states concatenated together.\n",
        "\n",
        "$$\n",
        "score(h_t, \\bar h_s) =\n",
        "\\begin{cases}\n",
        "h_t ^\\top \\bar h_s & dot \\\\\n",
        "h_t ^\\top \\textbf{W}_a \\bar h_s & general \\\\\n",
        "v_a ^\\top \\textbf{W}_a [ h_t ; \\bar h_s ] & concat\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The modular definition of these scoring functions gives us an opportunity to build specific attention module that can switch between the different score methods. The input to this module is always the hidden state (of the decoder RNN) and set of encoder outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "id": "PneeXGCcarI1"
      },
      "outputs": [],
      "source": [
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size, max_length=MAX_LENGTH):\n",
        "        super(Attn, self).__init__()\n",
        "        \n",
        "        self.method = method\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        seq_len = len(encoder_outputs)\n",
        "\n",
        "        # Create variable to store attention energies\n",
        "        attn_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\n",
        "        if USE_CUDA: attn_energies = attn_energies.cuda()\n",
        "\n",
        "        # Calculate energies for each encoder output\n",
        "        for i in range(seq_len):\n",
        "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
        "\n",
        "        # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\n",
        "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n",
        "    \n",
        "    def score(self, hidden, encoder_output):\n",
        "        \n",
        "        if self.method == 'dot':\n",
        "            # energy = hidden.dot(encoder_output)\n",
        "            energy = hidden@encoder_output.T\n",
        "            return energy\n",
        "        \n",
        "        elif self.method == 'general':\n",
        "            energy = self.attn(encoder_output)\n",
        "            # energy = hidden.dot(energy)\n",
        "            energy = hidden@energy.T\n",
        "            return energy\n",
        "        \n",
        "        elif self.method == 'concat':\n",
        "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
        "            # energy = self.other.dot(energy)\n",
        "            energy = self.other@energy.T\n",
        "            return energy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6wC4_p5arI2"
      },
      "source": [
        "Now we can build a decoder that plugs this Attn module in after the RNN to calculate attention weights, and apply those weights to the encoder outputs to get a context vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oRA8XDQzarI2"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        \n",
        "        # Keep parameters for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout_p = dropout_p\n",
        "        \n",
        "        # Define layers\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
        "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
        "        \n",
        "        # Choose attention model\n",
        "        if attn_model != 'none':\n",
        "            self.attn = Attn(attn_model, hidden_size)\n",
        "    \n",
        "    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n",
        "        # Note: we run this one step at a time\n",
        "        \n",
        "        # Get the embedding of the current input word (last output word)\n",
        "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
        "        \n",
        "        # Combine embedded input word and last context, run through RNN\n",
        "        rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
        "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
        "\n",
        "        # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
        "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
        "        \n",
        "        # Final output layer (next word prediction) using the RNN hidden state and context vector\n",
        "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
        "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
        "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
        "        \n",
        "        # Return final output, hidden state, and attention weights (for visualization)\n",
        "        return output, context, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEBlshpTarI3"
      },
      "source": [
        "### Testing the models\n",
        "\n",
        "To make sure the Encoder and Decoder model are working (and working together) we'll do a quick test with fake word inputs\n",
        "\n",
        "## Для тестирования модели оставим \"обычный\" dot-product (по условиям задачи) на 1-layer RNN, но остальные способы (general, concat) также работают и могут быть запущены альтернативно"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "scrolled": false,
        "id": "fRcnyS6QarI3",
        "outputId": "f0b1d96c-2582-4cd6-bd3a-19aea8af5c22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EncoderRNN(\n",
            "  (embedding): Embedding(10, 10)\n",
            "  (gru): GRU(10, 10)\n",
            ")\n",
            "AttnDecoderRNN(\n",
            "  (embedding): Embedding(10, 10)\n",
            "  (gru): GRU(20, 10, dropout=0.1)\n",
            "  (out): Linear(in_features=20, out_features=10, bias=True)\n",
            "  (attn): Attn()\n",
            ")\n",
            "torch.Size([1, 10]) torch.Size([1, 1, 10]) torch.Size([1, 1, 3])\n",
            "torch.Size([1, 10]) torch.Size([1, 1, 10]) torch.Size([1, 1, 3])\n",
            "torch.Size([1, 10]) torch.Size([1, 1, 10]) torch.Size([1, 1, 3])\n"
          ]
        }
      ],
      "source": [
        "encoder_test = EncoderRNN(10, 10, 1)\n",
        "decoder_test = AttnDecoderRNN('dot', 10, 10, 1) \n",
        "# decoder_test = AttnDecoderRNN('general', 10, 10, 2)\n",
        "# decoder_test = AttnDecoderRNN('concat', 10, 10, 2)\n",
        "print(encoder_test)\n",
        "print(decoder_test)\n",
        "\n",
        "encoder_hidden = encoder_test.init_hidden()\n",
        "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
        "if USE_CUDA:\n",
        "    encoder_test.cuda()\n",
        "    word_input = word_input.cuda()\n",
        "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
        "\n",
        "word_inputs = Variable(torch.LongTensor([1, 2, 3]))\n",
        "decoder_attns = torch.zeros(1, 3, 3)\n",
        "decoder_hidden = encoder_hidden\n",
        "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\n",
        "\n",
        "if USE_CUDA:\n",
        "    decoder_test.cuda()\n",
        "    word_inputs = word_inputs.cuda()\n",
        "    decoder_context = decoder_context.cuda()\n",
        "\n",
        "for i in range(3):\n",
        "    decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder_test(word_inputs[i], decoder_context, decoder_hidden, encoder_outputs)\n",
        "    print(decoder_output.size(), decoder_hidden.size(), decoder_attn.size())\n",
        "    decoder_attns[0, i] = decoder_attn.squeeze(0).cpu().data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1nb027LarI4"
      },
      "source": [
        "# Training\n",
        "\n",
        "## Defining a training iteration\n",
        "\n",
        "To train we first run the input sentence through the encoder word by word, and keep track of every output and the latest hidden state. Next the decoder is given the last hidden state of the decoder as its first hidden state, and the `<SOS>` token as its first input. From there we iterate to predict a next token from the decoder.\n",
        "\n",
        "### Teacher Forcing and Scheduled Sampling\n",
        "\n",
        "\"Teacher Forcing\", or maximum likelihood sampling, means using the real target outputs as each next input when training. The alternative is using the decoder's own guess as the next input. Using teacher forcing may cause the network to converge faster, but [when the trained network is exploited, it may exhibit instability](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf).\n",
        "\n",
        "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - you could think of it as having learned how to listen to the teacher's instructions, without learning how to venture out on its own.\n",
        "\n",
        "The solution to the teacher-forcing \"problem\" is known as [Scheduled Sampling](https://arxiv.org/abs/1506.03099), which simply alternates between using the target values and predicted values when training. We will randomly choose to use teacher forcing with an if statement while training - sometimes we'll feed use real target as the input (ignoring the decoder's output), sometimes we'll use the decoder's output."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "clip = 5.0\n",
        "\n",
        "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "\n",
        "    # Zero gradients of both optimizers\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    loss = 0 # Added onto for each word\n",
        "\n",
        "    # Get size of input and target sentences\n",
        "    input_length = input_variable.size()[0]\n",
        "    target_length = target_variable.size()[0]\n",
        "\n",
        "    # Run words through encoder\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
        "    \n",
        "    # Prepare input and output variables\n",
        "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
        "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
        "    decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
        "    if USE_CUDA:\n",
        "        decoder_input = decoder_input.cuda()\n",
        "        decoder_context = decoder_context.cuda()\n",
        "\n",
        "    # Choose whether to use teacher forcing\n",
        "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
        "    if use_teacher_forcing:\n",
        "        \n",
        "        # Teacher forcing: Use the ground-truth target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_variable[di])\n",
        "            decoder_input = target_variable[di] # Next target is next input\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use network's own prediction as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_variable[di])\n",
        "            \n",
        "            # Get most likely word index (highest value) from output\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            ni = topi[0][0]\n",
        "            \n",
        "            decoder_input = Variable(torch.LongTensor([[ni]])) # Chosen word is next input\n",
        "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
        "\n",
        "            # Stop at end of sentence (not necessary when using known targets)\n",
        "            if ni == EOS_token: break\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
        "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    \n",
        "    # return loss.data[0] / target_length\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "6gCdRDwdSbNt"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umU-W8ZearI5"
      },
      "source": [
        "Finally helper functions to print time elapsed and estimated time remaining, given the current time and progress."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def as_minutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def time_since(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
      ],
      "metadata": {
        "id": "LsxbTBFH9zC-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixl9Hpn3arI6"
      },
      "source": [
        "## Running training\n",
        "\n",
        "With everything in place we can actually initialize a network and start training.\n",
        "\n",
        "To start, we initialize models, optimizers, and a loss function (criterion)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Для реализации Attention'a оставим \"обычный\" dot-product (по условиям задачи)на 1-слойной RNN, но остальные способы (general, concat) также работают и могут быть запущены альтернативно"
      ],
      "metadata": {
        "id": "Qs5zI2MeoE6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_model = 'dot'\n",
        "# attn_model = 'general'\n",
        "# attn_model = 'concat'\n",
        "hidden_size = 256\n",
        "n_layers = 1\n",
        "dropout_p = 0.1\n",
        "\n",
        "# Initialize models\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers)\n",
        "decoder = AttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
        "\n",
        "# Move models to GPU\n",
        "if USE_CUDA:\n",
        "    encoder.cuda()\n",
        "    decoder.cuda()\n",
        "\n",
        "# Initialize optimizers and criterion\n",
        "learning_rate = 0.01\n",
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "zbSoxZuvSbK4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptdg1AxdarI7"
      },
      "source": [
        "Then set up variables for plotting and tracking progress:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring training\n",
        "n_epochs = 150000\n",
        "plot_every = 200\n",
        "print_every = 5000\n",
        "\n",
        "# Keep track of time elapsed and running averages\n",
        "start = time.time()\n",
        "plot_losses = []\n",
        "print_loss_total = 0 # Reset every print_every\n",
        "plot_loss_total = 0 # Reset every plot_every"
      ],
      "metadata": {
        "id": "s6bPoI2v_z--"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwQ40KQSarI8"
      },
      "source": [
        "To actually train, we call the train function many times, printing a summary as we go.\n",
        "\n",
        "*Note:* If you run this notebook you can train, interrupt the kernel, evaluate, and continue training later. You can comment out the lines above where the encoder and decoder are initialized (so they aren't reset) or simply run the notebook starting from the following cell."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Begin!\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    # Get training data for this cycle\n",
        "    training_pair = variables_from_pair(random.choice(pairs))\n",
        "    input_variable = training_pair[0]\n",
        "    target_variable = training_pair[1]\n",
        "\n",
        "    # Run the train function\n",
        "    loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "\n",
        "    # Keep track of loss\n",
        "    print_loss_total += loss\n",
        "    plot_loss_total += loss\n",
        "\n",
        "    if epoch == 0: continue\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print_loss_avg = print_loss_total / print_every\n",
        "        print_loss_total = 0\n",
        "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
        "        print(print_summary)\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        plot_loss_avg = plot_loss_total / plot_every\n",
        "        plot_losses.append(plot_loss_avg)\n",
        "        plot_loss_total = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPR7eXJl_z7-",
        "outputId": "f3f6cc20-46bc-40de-f813-5883007896ad"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 50s (- 53m 35s) (5000 3%) 3.8429\n",
            "3m 35s (- 50m 14s) (10000 6%) 3.5375\n",
            "5m 23s (- 48m 31s) (15000 10%) 3.3571\n",
            "7m 12s (- 46m 48s) (20000 13%) 3.2059\n",
            "9m 3s (- 45m 17s) (25000 16%) 3.0601\n",
            "10m 52s (- 43m 30s) (30000 20%) 2.9869\n",
            "12m 42s (- 41m 46s) (35000 23%) 2.8659\n",
            "14m 31s (- 39m 56s) (40000 26%) 2.8056\n",
            "16m 21s (- 38m 11s) (45000 30%) 2.7461\n",
            "18m 10s (- 36m 21s) (50000 33%) 2.6509\n",
            "20m 1s (- 34m 35s) (55000 36%) 2.6273\n",
            "21m 50s (- 32m 46s) (60000 40%) 2.5452\n",
            "23m 41s (- 30m 59s) (65000 43%) 2.5135\n",
            "25m 30s (- 29m 9s) (70000 46%) 2.4555\n",
            "27m 21s (- 27m 21s) (75000 50%) 2.4157\n",
            "29m 10s (- 25m 31s) (80000 53%) 2.3764\n",
            "31m 0s (- 23m 42s) (85000 56%) 2.2978\n",
            "32m 51s (- 21m 54s) (90000 60%) 2.2754\n",
            "34m 41s (- 20m 5s) (95000 63%) 2.2426\n",
            "36m 33s (- 18m 16s) (100000 66%) 2.2429\n",
            "38m 24s (- 16m 27s) (105000 70%) 2.1531\n",
            "40m 18s (- 14m 39s) (110000 73%) 2.1666\n",
            "42m 9s (- 12m 49s) (115000 76%) 2.1300\n",
            "44m 2s (- 11m 0s) (120000 80%) 2.1091\n",
            "45m 53s (- 9m 10s) (125000 83%) 2.0428\n",
            "47m 45s (- 7m 20s) (130000 86%) 2.0212\n",
            "49m 36s (- 5m 30s) (135000 90%) 2.0067\n",
            "51m 27s (- 3m 40s) (140000 93%) 1.9936\n",
            "53m 17s (- 1m 50s) (145000 96%) 1.9734\n",
            "55m 9s (- 0m 0s) (150000 100%) 1.9266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m2wK4gharI9"
      },
      "source": [
        "## Plotting training loss\n",
        "\n",
        "Plotting is done with matplotlib, using the array `plot_losses` that was created while training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "def show_plot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "\n",
        "show_plot(plot_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "fK5FKoa2u-Og",
        "outputId": "632841e6-df6c-46a8-f339-68e1073dd3c5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVm3amM8arI-"
      },
      "source": [
        "# Evaluating the network\n",
        "\n",
        "Evaluation is mostly the same as training, but there are no targets. Instead we always feed the decoder's predictions back to itself. Every time it predicts a word, we add it to the output string. If it predicts the EOS token we stop there. We also store the decoder's attention outputs for each step to display later."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence, max_length=MAX_LENGTH):\n",
        "    input_variable = variable_from_sentence(input_lang, sentence)\n",
        "    input_length = input_variable.size()[0]\n",
        "    \n",
        "    # Run through encoder\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
        "\n",
        "    # Create starting vectors for decoder\n",
        "    decoder_input = Variable(torch.LongTensor([[SOS_token]])) # SOS\n",
        "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
        "    if USE_CUDA:\n",
        "        decoder_input = decoder_input.cuda()\n",
        "        decoder_context = decoder_context.cuda()\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    \n",
        "    decoded_words = []\n",
        "    decoder_attentions = torch.zeros(max_length, max_length)\n",
        "    \n",
        "    # Run through decoder\n",
        "    for di in range(max_length):\n",
        "        decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
        "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
        "\n",
        "        # Choose top word from output\n",
        "        topv, topi = decoder_output.data.topk(1)\n",
        "        ni = topi[0][0]\n",
        "        if ni == EOS_token:\n",
        "            decoded_words.append('<EOS>')\n",
        "            break\n",
        "        else:\n",
        "            # decoded_words.append(output_lang.index2word[ni])\n",
        "            decoded_words.append(output_lang.index2word[topi.item()])\n",
        "            \n",
        "        # Next input is chosen word\n",
        "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
        "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
        "    \n",
        "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
      ],
      "metadata": {
        "id": "ANxACuLgAkQE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuVznpsearI_"
      },
      "source": [
        "We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_randomly(n=10):\n",
        "    for i in range(n):\n",
        "      pair = random.choice(pairs)\n",
        "    \n",
        "      output_words, decoder_attn = evaluate(pair[0])\n",
        "      output_sentence = ' '.join(output_words)\n",
        "    \n",
        "      print('>', pair[0])\n",
        "      print('=', pair[1])\n",
        "      print('<', output_sentence)\n",
        "      print('')"
      ],
      "metadata": {
        "id": "xWCzKhZVAkNI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_randomly()"
      ],
      "metadata": {
        "id": "y9keD59QAkJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d6cac0-1bad-405c-ea55-83c691c03a50"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> chto ty delal proshloi noch iu ?\n",
            "= what did you do last night ?\n",
            "< what did you do last night ? <EOS>\n",
            "\n",
            "> vam nravitsia vasha novaia rabota ?\n",
            "= are you pleased with your new job ?\n",
            "< do you like your new job ? <EOS>\n",
            "\n",
            "> ia byl nemnogo emotsionalen .\n",
            "= i was a bit emotional .\n",
            "< i was a bit a bit . <EOS>\n",
            "\n",
            "> ia byl v depressii .\n",
            "= i was depressed .\n",
            "< i was at . <EOS>\n",
            "\n",
            "> ona vsegda kurit .\n",
            "= she is always smoking .\n",
            "< she is always . . <EOS>\n",
            "\n",
            "> u menia chetyre tuza .\n",
            "= i have four aces .\n",
            "< i have a . . <EOS>\n",
            "\n",
            "> kak by ia eto sdelal ?\n",
            "= how would i do that ?\n",
            "< how did i do that ? <EOS>\n",
            "\n",
            "> ty sobiraesh sia srubit vse eti derev ia ?\n",
            "= are you going to cut down all these trees ?\n",
            "< are you going to get the the the ? ? ? <EOS>\n",
            "\n",
            "> u menia net prichin otkazyvat sia ot moego plana .\n",
            "= there is no reason that i should give up my plan .\n",
            "< i have no no idea to the the the . . <EOS>\n",
            "\n",
            "> mne nado napisat pis mo . u tebia est bumaga ?\n",
            "= i have to write a letter . do you have some paper ?\n",
            "< what have i have to eat for the question ? <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-lc0HAarJA"
      },
      "source": [
        "# Visualizing attention\n",
        "\n",
        "A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step.\n",
        "\n",
        "You could simply run `plt.matshow(attentions)` to see attention output displayed as a matrix, with the columns being input steps and rows being output steps:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_words, attentions = evaluate(\"chto ty delal proshloi noch iu ?\")\n",
        "plt.matshow(attentions.numpy())"
      ],
      "metadata": {
        "id": "M7P5SsoiAu6r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "3e511f5e-c76e-4229-c0bc-edd8f1d05189"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2c9f1f5f50>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rTIJgKDarJB"
      },
      "source": [
        "For a better viewing experience we will do the extra work of adding axes and labels:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_attention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "EqWnivdhLhHm"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateAndShowAttention(input_sentence_):\n",
        "    output_words, attentions = evaluate(input_sentence_)\n",
        "    print('input =', input_sentence_)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    show_attention(input_sentence_, output_words, attentions)"
      ],
      "metadata": {
        "id": "Z_U8VrRnCXSn"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateAndShowAttention(\"chto ty delal proshloi noch iu ?\")"
      ],
      "metadata": {
        "id": "IRZiKqJTA7sL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "733161b7-6187-43fb-9b71-c77cd58c7900"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = chto ty delal proshloi noch iu ?\n",
            "output = what did you do last night ? <EOS>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEcCAYAAAC7wh1hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeUElEQVR4nO3deZxcZZ3v8c+XKIIQgWsQlUVQQY2AgQTEEUYYwQlcFkdRNhW8YNTRC4qIODrIRZmrosNVBDUgCsqwiCJRozAoq4iSELaELZdFgo7cIEtA2dLf+8c5RaqLTld1+tSp6u7vm9d5pc5Sz/N0En55zrPKNhERscJqvS5ARES/SWCMiGiRwBgR0SKBMSKiRQJjRESLBMaIiBYJjBERLRIYIyJaJDBGRLR4Xq8LEGOPpKNtf1nSycBzpk7ZPrwHxYqoTAJjrIpby1/n9bQUEV2izJWO0ZK0NoDtx3pdlogqpI0xVpmkLSUtABYCiyTNl/T6XpcrhqfCTyS9rtdl6VcJjDEas4Ejbb/C9ibAJ4DTelymaO9twHbAYb0uSL9KYIzRWMv2ZY0T25cDa/WuONGhQymC4l6S0s8whATGGI27JP2rpE3L47PAXb0uVKycpCnA623/ArgUeHuPi9SXEhhjNP4HsD7w4/JYv7wW/eu9wDnl5++S1+khpVc6YgKRdDMw0/b95fmNwJ627+ttyfpL2hdixCT9lCEGdjfY3rvG4kSHJK0LfKMRFEtHAVOABMYmqTHGiEl6y3D3bV9RV1kiuiGBMWICkPQB4HLbd0oScAbwTuAe4GDbC3pZvn6TzpdYZZLeLOk/Jd0h6S5Jd0tKr3R/OoIiCAIcAGwNbAYcCXy9R2XqW2ljjNH4DvBxYD6wvMdlieE9Y/vp8vOewFm2HwQulfTlHparLyUwxmg8Uo6Hi/43IOllwEPAW4ETmu6t2Zsi9a8ExnFA0pHD3bf97xXnt2358TJJJ1KMYXyyKb/rq8yvKd+/Azal6e+t7bO6kdc4dCzFakiTgDm2F8KzHWlp/miRzpdxQNLnhrtv+39VnN9lw9y27X+oMr8yz+8DrwJuYMVru7P2Y+fK6X+TbT/UdG0tijiQlZGaTNjAKGl1YIvy9Pam9pfoQ5JuBaZ6ov6FrYCklwAfARorIC0ETrX9596Vqj9NyF5pSTsDdwKnAKcCd0j6+54WqgKS1pD0EUmnSjqjcXQxvyMkvahcxup0SddLeluXsrsFeGmX0h73JL0ZuK48Pas8AH5X3osmE7LGKGk+cKDt28vzLYBzbE/vbclGR9IPgduAA4HjgYOAW20f0aX8brT9Bkn/CHwI+CzwfdvbtvnqSPJozLKZDEwDfs/g9szMsumApGuBD7eOV5Q0Dfi27Tf2pmT9aaJ2vjy/ERQBbN8h6fm9LFBFXm37XZL2sX2mpP8Arupifip/3YNi+MfCcvBwlb5ScXoT1YuGGsRt+wZJk3tRoH42UQPjPEmnAz8ozw9ifOxf0mgnfVjSlsB/AS/pYn7zJV1CMVD40+X/YANVZtCYXihpM+BPtp8oz9cENqgyr3FOktZr7ngpL/43JmiT2nAm6m/Ih4FFwOHlsYjiVXCsmy1pPeBfgTkUP1c3B+8eChwDbGf7r8DqwPu7lNcPGRx0l5fXojMnAZdIeoukyeWxM/CL8l40mahtjEfY/lq7a9GepL2BRsfVFbZ/2qV8brA9reXajbbf0I38xiNJewJHU/RKm+IfzhO79Wc2lk3UwHh9aweBpAW2t+lVmUaj7gHeTfl+kWLvkLPLSwcA19n+ly7k9Z/AybbnlOf7AIfbfmvVeUVMqDZGSQdQ9NhuJmlO063JwF96U6pK9KrxfA9gmu0BAElnAguAygMjRVPH2ZJOKc/vo1iNOjog6Xzb7y4/f8n2p5ruXWK7W8OsxqQJFRiBa4A/USzM+dWm68uAm3pSogpUPbNlhNZlxT8q63QrE9v/F9ghe1ivss2bPu8GfKrpfP2ay9L3JlRgtH0vcC/wpl6XpRvK8ZjfBDawvaWkrYG9bX+hS1n+G7CgnCIoirbGY7qRkaR1gM+VeSDpCuB42490I79xaLg2s4nXntbGhOyVlvQOSXdKekTSo5KWSXq01+WqwGnApymH7di+Cdi/GxlJWo2il3gHikUkfgS8yfZ53ciPYmHVZcC7y+NRis2cojMvlLSNpOnAmuXnbRvnvS5cv5monS+Lgb1s31pDXnsBP2+0w3U5r+tsb9fckTRUb26F+c2zPaMbaQ+R11C90l372cabNgt/YHuXusoyFkyoV+kmf64jKJb2A/6PpB8BZ9i+rYt5LZX0KspXI0n7UrSpdsulko4CzgMeb1y03Y2OrL9J2tH21fDs3N+/dSEfJL1vqOtjeYmzBL6RmVA1RknvKD++hWJBgp8weN7tj7uU74sohrK8nyJofZdibvayivN5JTAb+DuKBUnvBg4q21YrJ+luhmifsv3KLuQ1DTiTFR08D1HsVVJ5p5mkk5tO16BY2PV62/tWnVedytlCW9i+senaJsDylp0DJ7yJFhgbbVJmxTzfBtvu2mbxkl5MMbzkY8CtwKuBr9s+edgvdpZ26zjGNSnajx+Hro5jXBP4Z2BHit/Tq4Bv2a68JifpBcC+FGsyrgs8QvFndnzVeQ2R97rAubZndjuvbirXA7gN2Nr24+W1S4B/sT0epsRWZkK9Stt+Pzw73u4I2w+X5+sxePhOZcqByIdQBMKzgO1tPyDphRQzD0YdGFkxjvE1FAOuL6II/O+lWI2mW86k6ARpbKZ0YHnt3V3I6yLgYeB6oO7azeMU88ErU85R/hDwBHC67a53/tl+WtKFFH8+3y1ri+snKD7XhAqMTbZuBEUA2w9J6taslwOBk2xf2bjQGGAr6dAqMmiMY5R0JbBt4xVd0nHAz6vIYyW2tD216fwySYu6lNdGddXYmpY6g6LmPRU4v+JsfgT8Fngx8FtJe9muY4uB0ymaW74LvI/07A9pogbG1ZpXGin/9e7W78XmzUGxtDvwKdu/qjivDYCnms6forsr0FwvaQfb1wJIeiPdW6XoGklb2b65S+k3a17q7BngXttLKs7jxY2pk+Xr7BWSHgY+ARzWmKVSNdu3qbAFxVCunbqRz1g3UQPjVyn+lW6szvIuBu+aNmqSPkzR/vZKSc0dBJOB31SZV5OzgN+Xr0sAbwe+16W8AKZTBKw/lOebALdLupmi/W/rCvPaETik7PB5kqKpoOo8gBVLnXXZMkmb2r7H9sXla+3LKTqVuh38v0NRc7y5dRmyKEyozpdmkqYCjU2bfm270lfAcqbGesD/ZvBskGVdGs7SyHdbVtQCrhxqcdIK83rFcPer7A1fWV4V53G17R0lLWNwb3sjCL+owrxeU6Z5R1VpjiDvF1IM43qn7Uvrzn8smLCBMSJiZSbklMCIiOEkMAKSZiWv5NXrvOrOr+6frRtU7IT5gKRbVnJfkr4uabGkm8qmprYSGAt1/gVJXsmrX/Ib84GRonNxuGFcu1MsubY5xc/7zU4STWCMiDGrHAo3XGfmPhQ7WLocVraupJe1S3dcDdeRtMo9SaP5bvJKXr3Ob/r0kW+JvskmmzBjxowR5XXPPfewdOnSUW2RO3PmTC9durSjZ+fPn7+QYnZQw2zbs0eQ3YYUq703LCmvDbu4yrgKjBET1bx59czqmzFj9KvMLV26tOPySnqirqXtmiUwRkTtahwmeD+wcdP5RnQw1z5tjBFRKwPLBwY6OiowB3hf2Tu9A/CI7bZrlKbGGBE1M65omxlJ5wA7A1MkLaHYF+j5ALa/Bcyl2M1yMfBXijVR20pgjIh6GQYqepO2fUCb+wY+MtJ0Exgjonb9PhU5gTEiamVgIIExImKw1BgjIprYrqrHuWtqD4ySHrO99gie3xl4yvY13StVRNQpNcbR2xl4DEhgjBgnqhqu0y2VD/CW9ElJh5efT5L06/LzP0g6u/x8gqQbJV0raYPy2l6SfidpgaRLJW0gaVOKndQ+LukGSdmfImKMKzpfOjt6pRszX65ixdL6M4C1y/1sdwKuBNYCrrX9hvL8A+WzVwM72N4GOBc42vY9wLcodtmbZvuqLpQ3Impmu6OjV7rxKj0fmC7pRRSbFl1PESB3Ag6n2LnuZ03P7lZ+3gg4r1wSaHXg7k4yKxfbHA/rykVMDGOg86XyGqPtpymC2iEU7YJXAbtQbDh/K/C0V/xTsJwVwflk4Bu2twI+CKzRYX6zbc/oxQocETFypv9rjN1aROIq4CiKV+WrKNoJF3j4n3QdVqx6cXDT9WUUW45GxDgxYHd09Eo3A+PLgN/a/jPFQpPt2gePA34oaT7QvIrlT4F/SudLxPjR7zXGrgzXsf0ryhUuyvMtmj6v3fT5AuCC8vNFwEVDpHUHUPmm6hHRK9WtrtMtY2EcY0SMI+7xUJxOJDBGRO0G+rxXOoExImqV1XUiIoaQudIREc16PBSnEwmMEVG71BgjIpoYWJ7AGBExWGqMEREtEhgjIpo4nS8REc+VGmNERIsExoiIJkWvdKYERkQMkkUkIiKa9XitxU4kMEZErRpbG/SzBMaIqF2G60REtEiNsQOSjgMeA14EXGn70pb7OwNH2d6z/tJFRJU8BrZP7YvA2GD72F6XISK6r9/3fOnWLoFtSfqMpDskXQ28prz2PUn7lp9nSrpN0vXAO3pVzoio3oA7O3qlJ4FR0nRgf2AasAewXcv9NYDTgL2A6cBL6y5jRHRHo1e6qu1Ty0rU7ZIWSzpmiPubSLpM0gJJN0nao12avaox7gRcaPuvth8F5rTcfy1wt+07Xfzu/GBlCUmaJWmepHldLG9EVKiqwChpEnAKsDswFThA0tSWxz4LnG97G4oK2ant0u2rNsZVYXs2MBtAUn83XEQEVNv5sj2w2PZdAJLOBfYBFjXnSNGxC7AO8Md2ifaqxngl8HZJa0qaTPHK3Ow2YFNJryrPD6i1dBHRNRW/Sm8I3Nd0vqS81uw44D2SlgBzgf/ZLtGeBEbb1wPnATcCvwCua7n/BDAL+HnZ+fJA7YWMiK4ZKNdkbHcAUxpNZeUxaxWyOwD4nu2NKPo0vi9p2NjXs1dp2ycAJwxz/5cUbY0RMc6MYLjOUtszhrl/P7Bx0/lG5bVmhwIzAWz/tuzcncIwFa6eDdeJiInL7uzowHXA5pI2k7Q6RedKa2fuH4C3Akh6HbAG8P+GS3TMd75ExNhiqpsrbfsZSR8FLgYmAWfYXijpeGCe7TnAJ4DTJH28zP4Qt2nATGCMiHpVPCXQ9lyKTpXma8c2fV4EvHkkaSYwRkStsuxYRMQQEhgjIlpkPcaIiEHc96vrJDBGRK1GMBSnZxIYI6J2Wag2IqJJleMYuyWBMSJql17piIhm2Vc6ImIICYwREYMNLE9gjIh4VjFcJ4ExImKQBMaIiEHS+RIR8Rzu5abRHUhgjIhapY0xImIIzpTAiIjB+rzCWN9mWJKOl/SxpvMTJB0h6URJt0i6WdJ+5b2dJf2s6dlvSDqkrrJGRBfZeKCzo1fq3CXwDOB9AOWervtTbI49DXgDsCtwoqSXjSRRSbMae85WXN6I6BKX0wLbHb1S26u07XskPShpG2ADYAGwI3CO7eXAnyVdAWwHPDqCdGcDswEk9XkFPSKy58tznQ4cAryUoga520qee4bBtdk1ulusiKhTvwfGOl+lAS4EZlLUCi8GrgL2kzRJ0vrA3wO/B+4Fpkp6gaR1KTfLjohxwMbLBzo6eqXWGqPtpyRdBjxse7mkC4E3ATdS1LCPtv1fAJLOB24B7qZ47Y6IcaLfa4y1Bsay02UH4F0ALn53Plkeg9g+Gji6zvJFRD36PC7WOlxnKrAY+JXtO+vKNyL6S6PzJb3SgO1FwCvryi8i+lSmBEZEtDIDPexY6UQCY0TULjXGiIgmWV0nImIoCYwREYO5v5sYExgjon55lY6IaGYzkIVqIyJWGAur69S9iERETHSm0oVqJc2UdLukxZKOWckz75a0SNJCSf/RLs3UGCOifhXVGCVNAk6hWMJwCXCdpDnlTLvGM5sDnwbebPshSS9pl25qjBFRs87mSXf4ur09sNj2XbafAs4F9ml55gPAKbYfArD9QLtEExgjonYDA+7oAKY0ti4pj1ktSW0I3Nd0vqS81mwLYAtJv5F0raSZ7cqXV+mIqJXLNsYOLbU9Y5RZPg/YHNgZ2Ai4UtJWth9e2RdSY4yI2lX4Kn0/sHHT+UbltWZLgDm2n7Z9N3AHRaBcqQTGiKhdhYHxOmBzSZtJWp1i99E5Lc/8hKK2iKQpFK/Wdw2XaF6lI6Jm1S1Ca/sZSR+l2ENqEnCG7YWSjgfm2Z5T3nubpEXAcuCTth8cLt2+C4ySjgMes/2VXpclIrqg4tV1bM8F5rZcO7bps4Ejy6MjfRcYI2J8M+DlmfnSlqTPSLpD0tXAa8pr08qu9ZskXShpvR4XMyIq0u97vvQ8MEqaTtFgOg3Yg2LPaYCzgE/Z3hq4GfjcSr4/qzHGqY7yRsQodRgUJ8RmWMPYCbjQ9l8BJM0B1gLWtX1F+cyZwA+H+rLt2cDs8rv9XT+PCGBE4xh7oh8CY0RMMFldp70rgbdLWlPSZGAv4HHgIUk7lc+8F7hiZQlExNiRfaU7YPt6SecBNwIPUAzYBDgY+JakF1IMxnx/j4oYEVWycRaqbc/2CcAJQ9zaoe6yRET3Zc+XiIgW/d7GmMAYEfXKvtIREYONhT1fEhgjomZmYHl/NzImMEZEvfIqHRExhATGiIjB+jwuJjBGRL3S+RIR0Wpkm2H1RAJjRNTMDGRKYETEYHmVjoholcAYEbGC08YYEfFcfV5hTGCMiLr1dhHaTiQwRkS9THqlIyKambQxRkQ8R7+/Ste6GZakx1bxex8r936JiDHPZdd0B0eP9MMugZ34GJDAGDEeOLsEDknS2sBFwHrA84HP2r5I0lrA+cBGwCTg88AGwMuByyQttb1LL8ocEdUZWN7fr9K9amN8Avgn249KmgJcK2kOMBP4o+3/DiBpHduPSDoS2MX20h6VNyIqMhZW1+nVq7SAf5N0E3ApsCFFzfBmYDdJX5K0k+1H2iYkzZI0T9K87hY5IioxBl6lexUYDwLWB6bbngb8GVjD9h3AthQB8guSjm2XkO3ZtmfYntHVEkdERToLihOujRFYB3jA9tOSdgFeASDp5cBfbP9A0sPAYeXzy4DJQF6lI8aBfn+V7lVgPBv4qaSbgXnAbeX1rYATJQ0ATwMfLq/PBn4p6Y/pfIkY+zLAu4nttctflwJvGuKRe4CLh/jeycDJXS1cRNSi6tV1JM0EvkYxkuV0219cyXPvBC4AtrM9bJ/EWBnHGBHjSFVtjJImAacAuwNTgQMkTR3iucnAEcDvOilfAmNE1KzSzpftgcW277L9FHAusM8Qz30e+BLFUMG2Ehgjol7lq3QnRwc2BO5rOl9SXnuWpG2BjW3/vNMiZhGJiKjdCHqlp7SMUZ5te3anX5a0GvDvwCGdly6BMSJqNsKZL0vbjFG+H9i46Xyj8lrDZGBL4HJJAC8F5kjae7gOmATGiKiZcXUL1V4HbC5pM4qAuD9w4LM5FbPnpjTOJV0OHJVe6YjoLwYPdHa0Tcp+BvgoxTC/W4HzbS+UdLykvVe1iKkxRkTtqpz5YnsuMLfl2pDTiW3v3EmaCYwRXTB77iW15rfbbgfXks8dd9xTSTqZEhgR0WQsLDuWwBgR9bIZWJ5dAiMiBkuNMSJiMJPAGBHxLDttjBERLYw7GaTYQwmMEVG71BgjIloMVDclsCsSGCOiVsVai/0dGGuZK13OW9y1zTPHSTpqiOvrSvrn7pUuImpX9MC0P3qklsBo+1jbl67i19cFEhgjxhF3+F+vVBoYJW0q6VZJp0laKOkSSWtK+p6kfctn9pB0m6T5kr4u6WdNSUyVdLmkuyQdXl77IvAqSTdIOrHK8kZEb0zEfaU3Bw6w/QFJ5wPvbNyQtAbwbeDvbd8t6ZyW774W2IViccnbJX0TOAbY0va0LpQ1ImpnBgaW97oQw+rGq/Tdtm8oP88HNm2691rgLtt3l+etgfHntp8st1d9ANigXWaSZkma17L8eUT0qcYA74lWY3yy6fNyYM1RfLdt+cr9H2YDSOrvwVERAfT/OMa6V/C+HXilpE3L8/06+M4yilfriBgn+r3GWGtgtP03ih7mX0qaTxH0HmnznQeB30i6JZ0vEeNBh0N1xsurtO17KHbkapx/ZYjHLrP9WhVbdp0CzCufPa4lreZ0DiQixg3T3wO8ezHz5QOSDgZWBxZQ9FJHxARhZ0rgc9g+CTip7nwjol/0tv2wE5krHRG16/e50gmMEVG71BgjIlokMEZENOvxUJxOJDBGRK0MDLi/50onMEZEzdIrHTEhzdrjbbXmV1egmTFjRiXpJDBGRLRIYIyIaFL0vWQcY0REE+NMCYyIGKyX+7l0IoExImqXNsaIiEH6f1/pBMaIqFVjz5d+VvfWBhERlW5tIGmmpNslLZZ0zBD3j5S0SNJNkn4l6RXt0kxgjIjaDQwMdHS0I2kSxU4AuwNTgQMkTW15bAEww/bWwAXAl9ul29eBUdJrJV0j6WZJV0ia0usyRcRoGTzQ2dHe9sBi23fZfgo4F9hnUG72Zbb/Wp5eC2zULtG+Doyl99jeCrgG+FCvCxMRo+cO/wOmNPaNL49ZLUltCNzXdL6kvLYyhwK/aFe+vu58sX1b0+kLgAd7VZaIqMYIO1+W2q5kgrak9wAzgLe0e7avA2ODpH+kaEN4U6/LEhGjV2Gv9P3Axk3nG5XXBpG0K/AZ4C22n2yXaN8HRkmrAd8BdrH98BD3ZwGt1euI6FuVjmO8Dthc0mYUAXF/YNB2y5K2odiNdKbtBzpJtO8DI/By4BHbdw510/ZsYDaApP4eHBURQHXbp9p+RtJHgYuBScAZthdKOh6YZ3sOcCKwNvDDYjt7/mB77+HSHQuB8SHgE70uRERUo+oB3rbnAnNbrh3b9HnXkaY5Fnql1wEO63UhIqIqXrHvS7ujR/q+xmj7j8C+vS5HRFTHZK50RMQg/T5XOoExImrmyjpfuiWBMSJqla0NIiKGkFfpiIgWCYwREYP0dihOJxIYI6J22QwrIqKJDQMDy3tdjGElMEZEzTrftqBXEhgjonYJjBERLRIYIyJaZIB3RESzHq+c04kExoiolYGB1BgjIgbLq3RExCAZrhMR8RwJjBERTare86UbEhgjombGfT4lcNSbYUm6XNLtkm4ojwua7s2SdFt5/F7Sjk339pS0QNKNkhZJ+uBoyxIRY4M7/K9XVqnGKGl14Pm2Hy8vHWR7XsszewIfBHa0vVTStsBPJG0PPEixF/T2tpdIegGwafm99Ww/tGo/TkSMBf3+Kj2iGqOk10n6KnA7sEWbxz8FfNL2UgDb1wNnAh8BJlME5QfLe0/avr383n6SbpH0CUnrj6R8ETE22O7o6JW2gVHSWpLeL+lq4DRgEbC17QVNj53d9Cp9Ynnt9cD8luTmAa+3/RdgDnCvpHMkHSRpNQDb3wJ2B14IXCnpAkkzG/eHKN8sSfMkzRvqfkT0lyLoDXR09Eonr9J/Am4CDrN920qeec6rdDu2D5O0FbArcBSwG3BIee8+4POSvkARJM+gCKp7D5HObIrXciT1d/08IoDx8Sq9L3A/8GNJx0p6RYdpLwKmt1ybDixsnNi+2fZJFEHxnc0Plm2RpwJfB84HPt1hvhHR5wYGBjo6eqVtYLR9ie39gJ2AR4CLJF0qadM2X/0y8CVJLwaQNI2iRniqpLUl7dz07DTg3vK5t0m6CfgCcBkw1fbHbC8kIsaHxkIS7Y4e6bhX2vaDwNeAr5W1ueaBSGdL+lv5eantXW3PkbQhcE35irsMeI/tP0maDBwt6dvA34DHKV+jKTpk9rJ976h+sojoU8aMw7nStn/f9HnnYZ77JvDNIa4vA/ZYyXdaO2wiYhzJzJeIiCEkMEZEtEhgjIgYxNk+NSKi2VhoYxz1IhIRESNW4XCdcmbc7ZIWSzpmiPsvkHReef93HQw1TGCMiLp1urZO+8AoaRJwCsUMuanAAZKmtjx2KPCQ7VcDJwFfapduAmNE1K7CudLbA4tt32X7KeBcYJ+WZ/ahWMAG4ALgrZI0XKJpY4yI2lU43W9D4L6m8yXAG1f2jO1nJD0CvBhYurJEx1tgXEo5tXCEpjDMb1LFklfyqjy/NhWgKvPqdK2E4Vxc5t2JNVpWzppdLhzTVeMqMNpepfUbJc2zPaPq8iSv5NXP+dX9szXYnllhcvcDGzedb1ReG+qZJZKeB6xDuRbsyqSNMSLGsuuAzSVtVu4ssD/FWq/N5gAHl5/3BX7tNuOFxlWNMSImlrLN8KMUr+eTgDNsL5R0PDDP9hzgO8D3JS0G/kIRPIeVwFjoeptF8kpefZhf3T9bV9ieC8xtuXZs0+cngHeNJE31+wj0iIi6pY0xIqJFAmNERIsExoiIFgmMEREtEhgjIlokMEZEtEhgjIho8f8BGVSYjCTC17wAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateAndShowAttention(\"u menia net prichin otkazyvat sia ot moego plana .\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "D8kQ44nCPWcO",
        "outputId": "02e8fcbd-7eb7-4066-aa5f-e1004257430d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = u menia net prichin otkazyvat sia ot moego plana .\n",
            "output = i have no no idea to the the the . . <EOS>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Общий вывод по сравнению вариантов - MLP отработал качественнее (быстрее и с меньшим лоссом), визуально качество перевода также было выше у MLP:\n",
        "## 1. Multilayer Perceptron: 40m 2s (150000 100%) 1.4061\n",
        "## 2. Dot-product Attention @1-layer RNN: 55m 9s (150000 100%) 1.9266\n",
        "\n",
        "## Возможно, более высокого качества модели seq2seq на Dot-Product Attention удалось бы добиться с увеличением количества слоев в RNN (>=2) или с использованием других способов обработки скрытого состояния ('general' или 'concat')."
      ],
      "metadata": {
        "id": "PlZ16wikrFYc"
      }
    }
  ]
}