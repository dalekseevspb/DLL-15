{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## AlekseevDP(DSU-4, DLL-15)_HW#6_Рекуррентные_НС(#2)_RNN#2"
      ],
      "metadata": {
        "id": "GoFSUmK0Y053"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1. Сгенерировать последовательности, которые бы состояли из цифр (от 0 до 9) и задавались следующим образом:\n",
        "- x - последовательность цифр\n",
        "- y1 = x1, y(i) = x(i) + x(1).\n",
        "Если y(i) >= 10, то y(i) = y(i) - 10 \n",
        "\n",
        "[Примечание: из вопросов по ДЗ на сайте:\n",
        "- \"Вопрос студента: \"В данном случае под x1 и y1 понимается x[0] и y[0]?\"\n",
        "- \"Ответ преподавателя: \"Да\"]\n",
        "\n",
        "Задача:\n",
        "- научить модель предсказывать y(i) по x(i)\n",
        "- попробовать RNN, LSTM, GRU\n"
      ],
      "metadata": {
        "id": "FswbsYGLZCPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "import random\n",
        "from random import randint, seed, shuffle"
      ],
      "metadata": {
        "id": "lEPeOqplaxxf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## выведем активное устройство для обучения модели\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (DEVICE)"
      ],
      "metadata": {
        "id": "ZYQr0VzjyvGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc355ec2-1162-4120-8a02-6968acc148c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Задание 1. Пример:\n",
        "i    = 0   1   2   3   4   5   6   7   8   9\n",
        "\n",
        "X[i] = 5   7   2   8   3   9   5   0   4   6\n",
        "\n",
        "Y[i] = 5   2   7   3   8   4   0   5   9   1\"\"\""
      ],
      "metadata": {
        "id": "hP7GKOxdRY2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# зададим количество сэмплов, а также инициализируем X и Y\n",
        "samples = 100\n",
        "X = torch.zeros(samples, dtype=int)\n",
        "Y = torch.zeros(samples, dtype=int)"
      ],
      "metadata": {
        "id": "E2NRz8ccdkgr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сгенерируем X, предварительно зафиксировав генератор случайных чисел (для воспроизводимости результатов)\n",
        "random.seed(12)\n",
        "for i in range(samples):\n",
        "  X[i] = randint(0, 9)"
      ],
      "metadata": {
        "id": "-y99f8CNSZYJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mz6nYJeVY0CL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d53eac9-e6ee-49a2-fba2-f0dcd96308c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 4, 8, 5, 2, 6, 0, 5, 7, 4, 7, 9, 3, 8, 0, 9, 2, 7, 5, 2, 5, 3, 0, 9,\n",
              "        3, 1, 8, 5, 6, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X[:30]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# теперь на основании X сгенерируем Y\n",
        "Y[0] = X[0]\n",
        "for i in range(1, samples):\n",
        "  Y[i] = X[i] + X[0]\n",
        "  if Y[i] >= 10:\n",
        "     Y[i] -= 10"
      ],
      "metadata": {
        "id": "uwPSU1LFk8hM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y[:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82TweEAdpPwh",
        "outputId": "89656a5d-0cce-48b2-e24a-38e5df8977f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 1, 5, 2, 9, 3, 7, 2, 4, 1, 4, 6, 0, 5, 7, 6, 9, 4, 2, 9, 2, 0, 7, 6,\n",
              "        0, 8, 5, 2, 3, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "knUlhLEw1T83"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)"
      ],
      "metadata": {
        "id": "apq2XURf1VXd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpCce0Na1yTo",
        "outputId": "4d5d045c-bac5-4755-fb69-389850fffbe0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([70]), torch.Size([70]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og88rwpu11Vn",
        "outputId": "98e86e45-7bb5-4afe-a16a-3459caa3601b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([30]), torch.Size([30]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=20"
      ],
      "metadata": {
        "id": "XD3ziXvXEfsF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "data_train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "data_test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "FVA7CvS0y5tZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding = torch.nn.Embedding(10, 20)\n",
        "        self.rnn = torch.nn.RNN(20, 128, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, seq, state=None):\n",
        "        embed = self.embedding(seq)\n",
        "        o, s = self.rnn(embed)\n",
        "        out = self.linear(o)\n",
        "        return out"
      ],
      "metadata": {
        "id": "p9Gqz55Wyl43"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()"
      ],
      "metadata": {
        "id": "lsAVPjT4yjMM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "LEARNING_RATE = 0.001"
      ],
      "metadata": {
        "id": "yAw-lYHPw2P1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "z7OYHkChycD4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# зададим функцию для обучения модели\n",
        "def train_model():\n",
        "  for ep in range(num_epochs):\n",
        "    train_iters, train_passed  = 0, 0\n",
        "    train_loss, train_acc = 0., 0.\n",
        "    start=time.time()\n",
        "    \n",
        "    model.train()\n",
        "    for x, y in data_train:\n",
        "        optimizer.zero_grad()\n",
        "        answers = model(x)\n",
        "        loss = criterion(answers, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "                \n",
        "        train_acc += (answers.argmax(dim=1) == y).sum().item()\n",
        "        train_iters += 1\n",
        "        train_passed += len(x)\n",
        "    \n",
        "    test_iters, test_passed  = 0, 0\n",
        "    test_loss, test_acc = 0., 0.\n",
        "    model.eval()\n",
        "    for x, y in data_test:\n",
        "        answers = model(x)\n",
        "        loss = criterion(answers, y)\n",
        "        test_loss += loss.item()\n",
        "        \n",
        "        test_acc += (answers.argmax(dim=1) == y).sum().item()\n",
        "        test_iters += 1\n",
        "        test_passed += len(x)\n",
        "        \n",
        "    print(\"ep: {}, taked: {:.3f}, train_loss: {:.3f}, train_acc: {:.3f}, test_loss: {:.3f}, test_acc: {:.3f}\".format(\n",
        "        ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n",
        "        test_loss / test_iters, test_acc / test_passed)\n",
        "    )"
      ],
      "metadata": {
        "id": "R8Q7k2bgkG3t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqcGZZ0-kl4l",
        "outputId": "8ac479fb-9d0f-4b76-ec50-f0bb4eee24ab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 0, taked: 0.020, train_loss: 2.259, train_acc: 0.214, test_loss: 2.248, test_acc: 0.200\n",
            "ep: 1, taked: 0.011, train_loss: 2.255, train_acc: 0.229, test_loss: 2.244, test_acc: 0.200\n",
            "ep: 2, taked: 0.011, train_loss: 2.251, train_acc: 0.229, test_loss: 2.241, test_acc: 0.233\n",
            "ep: 3, taked: 0.014, train_loss: 2.246, train_acc: 0.229, test_loss: 2.237, test_acc: 0.233\n",
            "ep: 4, taked: 0.012, train_loss: 2.242, train_acc: 0.243, test_loss: 2.233, test_acc: 0.233\n",
            "ep: 5, taked: 0.012, train_loss: 2.237, train_acc: 0.257, test_loss: 2.229, test_acc: 0.233\n",
            "ep: 6, taked: 0.013, train_loss: 2.233, train_acc: 0.257, test_loss: 2.225, test_acc: 0.233\n",
            "ep: 7, taked: 0.012, train_loss: 2.229, train_acc: 0.271, test_loss: 2.221, test_acc: 0.233\n",
            "ep: 8, taked: 0.011, train_loss: 2.224, train_acc: 0.271, test_loss: 2.218, test_acc: 0.233\n",
            "ep: 9, taked: 0.011, train_loss: 2.220, train_acc: 0.271, test_loss: 2.214, test_acc: 0.233\n",
            "ep: 10, taked: 0.011, train_loss: 2.215, train_acc: 0.286, test_loss: 2.210, test_acc: 0.233\n",
            "ep: 11, taked: 0.011, train_loss: 2.211, train_acc: 0.300, test_loss: 2.206, test_acc: 0.233\n",
            "ep: 12, taked: 0.011, train_loss: 2.207, train_acc: 0.314, test_loss: 2.202, test_acc: 0.233\n",
            "ep: 13, taked: 0.012, train_loss: 2.202, train_acc: 0.343, test_loss: 2.199, test_acc: 0.233\n",
            "ep: 14, taked: 0.012, train_loss: 2.198, train_acc: 0.371, test_loss: 2.195, test_acc: 0.267\n",
            "ep: 15, taked: 0.012, train_loss: 2.194, train_acc: 0.386, test_loss: 2.191, test_acc: 0.300\n",
            "ep: 16, taked: 0.012, train_loss: 2.189, train_acc: 0.414, test_loss: 2.187, test_acc: 0.300\n",
            "ep: 17, taked: 0.015, train_loss: 2.185, train_acc: 0.414, test_loss: 2.184, test_acc: 0.300\n",
            "ep: 18, taked: 0.014, train_loss: 2.181, train_acc: 0.414, test_loss: 2.180, test_acc: 0.333\n",
            "ep: 19, taked: 0.015, train_loss: 2.176, train_acc: 0.414, test_loss: 2.176, test_acc: 0.367\n",
            "ep: 20, taked: 0.012, train_loss: 2.172, train_acc: 0.414, test_loss: 2.172, test_acc: 0.367\n",
            "ep: 21, taked: 0.012, train_loss: 2.168, train_acc: 0.414, test_loss: 2.169, test_acc: 0.400\n",
            "ep: 22, taked: 0.012, train_loss: 2.163, train_acc: 0.414, test_loss: 2.165, test_acc: 0.467\n",
            "ep: 23, taked: 0.012, train_loss: 2.159, train_acc: 0.429, test_loss: 2.161, test_acc: 0.467\n",
            "ep: 24, taked: 0.012, train_loss: 2.155, train_acc: 0.443, test_loss: 2.158, test_acc: 0.533\n",
            "ep: 25, taked: 0.011, train_loss: 2.151, train_acc: 0.443, test_loss: 2.154, test_acc: 0.533\n",
            "ep: 26, taked: 0.012, train_loss: 2.146, train_acc: 0.457, test_loss: 2.150, test_acc: 0.533\n",
            "ep: 27, taked: 0.012, train_loss: 2.142, train_acc: 0.529, test_loss: 2.146, test_acc: 0.533\n",
            "ep: 28, taked: 0.013, train_loss: 2.138, train_acc: 0.529, test_loss: 2.143, test_acc: 0.533\n",
            "ep: 29, taked: 0.014, train_loss: 2.134, train_acc: 0.529, test_loss: 2.139, test_acc: 0.533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(f'x_test: {X_test[i]}\\ny_test: {y_test[i]} \\ny_pred: {model(X_test[i].unsqueeze(-1)).argmax(dim=1)}\\n------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0lmioYF0xH9",
        "outputId": "8e671c6e-e7a7-4301-e778-18571b1c3ba5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test: 2\n",
            "y_test: 9 \n",
            "y_pred: tensor([9])\n",
            "------------\n",
            "x_test: 6\n",
            "y_test: 3 \n",
            "y_pred: tensor([3])\n",
            "------------\n",
            "x_test: 9\n",
            "y_test: 6 \n",
            "y_pred: tensor([6])\n",
            "------------\n",
            "x_test: 1\n",
            "y_test: 8 \n",
            "y_pred: tensor([6])\n",
            "------------\n",
            "x_test: 6\n",
            "y_test: 3 \n",
            "y_pred: tensor([3])\n",
            "------------\n",
            "x_test: 4\n",
            "y_test: 1 \n",
            "y_pred: tensor([2])\n",
            "------------\n",
            "x_test: 6\n",
            "y_test: 3 \n",
            "y_pred: tensor([3])\n",
            "------------\n",
            "x_test: 7\n",
            "y_test: 4 \n",
            "y_pred: tensor([3])\n",
            "------------\n",
            "x_test: 3\n",
            "y_test: 0 \n",
            "y_pred: tensor([0])\n",
            "------------\n",
            "x_test: 4\n",
            "y_test: 1 \n",
            "y_pred: tensor([2])\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Мы видим, что на небольшом исходном датасете (100 сэмплов), размере батча 20 сэмплов, небольшом количестве эпох (30) и оптимизаторе SGD точность предсказаний ячейкой RNN получается невысокой (53%). Попробуем увеличить количество эпох до 100, остальные параметры без изменений."
      ],
      "metadata": {
        "id": "graLxIl46Qah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "0-C_q_6N6PTa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "EthpDvyA0xFC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyIJh4qh7SVR",
        "outputId": "19f4da45-fda9-4f86-c48a-b68dc3ff5775"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 0, taked: 0.016, train_loss: 2.339, train_acc: 0.071, test_loss: 2.358, test_acc: 0.000\n",
            "ep: 1, taked: 0.011, train_loss: 2.334, train_acc: 0.071, test_loss: 2.353, test_acc: 0.033\n",
            "ep: 2, taked: 0.011, train_loss: 2.329, train_acc: 0.086, test_loss: 2.349, test_acc: 0.033\n",
            "ep: 3, taked: 0.012, train_loss: 2.324, train_acc: 0.086, test_loss: 2.345, test_acc: 0.033\n",
            "ep: 4, taked: 0.011, train_loss: 2.319, train_acc: 0.086, test_loss: 2.340, test_acc: 0.033\n",
            "ep: 5, taked: 0.011, train_loss: 2.314, train_acc: 0.100, test_loss: 2.336, test_acc: 0.033\n",
            "ep: 6, taked: 0.011, train_loss: 2.309, train_acc: 0.100, test_loss: 2.331, test_acc: 0.033\n",
            "ep: 7, taked: 0.011, train_loss: 2.304, train_acc: 0.114, test_loss: 2.327, test_acc: 0.033\n",
            "ep: 8, taked: 0.011, train_loss: 2.299, train_acc: 0.114, test_loss: 2.323, test_acc: 0.033\n",
            "ep: 9, taked: 0.011, train_loss: 2.294, train_acc: 0.114, test_loss: 2.318, test_acc: 0.033\n",
            "ep: 10, taked: 0.011, train_loss: 2.289, train_acc: 0.129, test_loss: 2.314, test_acc: 0.033\n",
            "ep: 11, taked: 0.011, train_loss: 2.284, train_acc: 0.143, test_loss: 2.310, test_acc: 0.033\n",
            "ep: 12, taked: 0.011, train_loss: 2.279, train_acc: 0.143, test_loss: 2.305, test_acc: 0.033\n",
            "ep: 13, taked: 0.011, train_loss: 2.274, train_acc: 0.186, test_loss: 2.301, test_acc: 0.033\n",
            "ep: 14, taked: 0.011, train_loss: 2.269, train_acc: 0.186, test_loss: 2.297, test_acc: 0.100\n",
            "ep: 15, taked: 0.010, train_loss: 2.264, train_acc: 0.200, test_loss: 2.292, test_acc: 0.133\n",
            "ep: 16, taked: 0.011, train_loss: 2.259, train_acc: 0.243, test_loss: 2.288, test_acc: 0.233\n",
            "ep: 17, taked: 0.011, train_loss: 2.254, train_acc: 0.243, test_loss: 2.284, test_acc: 0.267\n",
            "ep: 18, taked: 0.015, train_loss: 2.249, train_acc: 0.243, test_loss: 2.279, test_acc: 0.267\n",
            "ep: 19, taked: 0.011, train_loss: 2.244, train_acc: 0.257, test_loss: 2.275, test_acc: 0.267\n",
            "ep: 20, taked: 0.013, train_loss: 2.239, train_acc: 0.257, test_loss: 2.271, test_acc: 0.267\n",
            "ep: 21, taked: 0.011, train_loss: 2.234, train_acc: 0.271, test_loss: 2.266, test_acc: 0.267\n",
            "ep: 22, taked: 0.011, train_loss: 2.229, train_acc: 0.286, test_loss: 2.262, test_acc: 0.267\n",
            "ep: 23, taked: 0.011, train_loss: 2.225, train_acc: 0.286, test_loss: 2.258, test_acc: 0.267\n",
            "ep: 24, taked: 0.012, train_loss: 2.220, train_acc: 0.300, test_loss: 2.254, test_acc: 0.267\n",
            "ep: 25, taked: 0.011, train_loss: 2.215, train_acc: 0.300, test_loss: 2.249, test_acc: 0.267\n",
            "ep: 26, taked: 0.012, train_loss: 2.210, train_acc: 0.300, test_loss: 2.245, test_acc: 0.267\n",
            "ep: 27, taked: 0.011, train_loss: 2.205, train_acc: 0.329, test_loss: 2.241, test_acc: 0.267\n",
            "ep: 28, taked: 0.011, train_loss: 2.200, train_acc: 0.343, test_loss: 2.237, test_acc: 0.267\n",
            "ep: 29, taked: 0.017, train_loss: 2.195, train_acc: 0.357, test_loss: 2.232, test_acc: 0.333\n",
            "ep: 30, taked: 0.020, train_loss: 2.191, train_acc: 0.371, test_loss: 2.228, test_acc: 0.367\n",
            "ep: 31, taked: 0.012, train_loss: 2.186, train_acc: 0.386, test_loss: 2.224, test_acc: 0.367\n",
            "ep: 32, taked: 0.011, train_loss: 2.181, train_acc: 0.400, test_loss: 2.220, test_acc: 0.367\n",
            "ep: 33, taked: 0.015, train_loss: 2.176, train_acc: 0.400, test_loss: 2.216, test_acc: 0.400\n",
            "ep: 34, taked: 0.015, train_loss: 2.171, train_acc: 0.414, test_loss: 2.211, test_acc: 0.400\n",
            "ep: 35, taked: 0.011, train_loss: 2.167, train_acc: 0.414, test_loss: 2.207, test_acc: 0.433\n",
            "ep: 36, taked: 0.011, train_loss: 2.162, train_acc: 0.443, test_loss: 2.203, test_acc: 0.433\n",
            "ep: 37, taked: 0.011, train_loss: 2.157, train_acc: 0.457, test_loss: 2.199, test_acc: 0.467\n",
            "ep: 38, taked: 0.011, train_loss: 2.152, train_acc: 0.457, test_loss: 2.195, test_acc: 0.467\n",
            "ep: 39, taked: 0.011, train_loss: 2.148, train_acc: 0.471, test_loss: 2.191, test_acc: 0.467\n",
            "ep: 40, taked: 0.012, train_loss: 2.143, train_acc: 0.486, test_loss: 2.186, test_acc: 0.467\n",
            "ep: 41, taked: 0.013, train_loss: 2.138, train_acc: 0.500, test_loss: 2.182, test_acc: 0.500\n",
            "ep: 42, taked: 0.012, train_loss: 2.133, train_acc: 0.500, test_loss: 2.178, test_acc: 0.500\n",
            "ep: 43, taked: 0.014, train_loss: 2.129, train_acc: 0.514, test_loss: 2.174, test_acc: 0.500\n",
            "ep: 44, taked: 0.012, train_loss: 2.124, train_acc: 0.514, test_loss: 2.170, test_acc: 0.500\n",
            "ep: 45, taked: 0.012, train_loss: 2.119, train_acc: 0.529, test_loss: 2.166, test_acc: 0.500\n",
            "ep: 46, taked: 0.012, train_loss: 2.114, train_acc: 0.543, test_loss: 2.162, test_acc: 0.500\n",
            "ep: 47, taked: 0.011, train_loss: 2.110, train_acc: 0.571, test_loss: 2.157, test_acc: 0.500\n",
            "ep: 48, taked: 0.011, train_loss: 2.105, train_acc: 0.571, test_loss: 2.153, test_acc: 0.533\n",
            "ep: 49, taked: 0.011, train_loss: 2.100, train_acc: 0.571, test_loss: 2.149, test_acc: 0.533\n",
            "ep: 50, taked: 0.015, train_loss: 2.096, train_acc: 0.571, test_loss: 2.145, test_acc: 0.533\n",
            "ep: 51, taked: 0.018, train_loss: 2.091, train_acc: 0.586, test_loss: 2.141, test_acc: 0.533\n",
            "ep: 52, taked: 0.010, train_loss: 2.086, train_acc: 0.614, test_loss: 2.137, test_acc: 0.533\n",
            "ep: 53, taked: 0.010, train_loss: 2.082, train_acc: 0.614, test_loss: 2.133, test_acc: 0.533\n",
            "ep: 54, taked: 0.011, train_loss: 2.077, train_acc: 0.614, test_loss: 2.129, test_acc: 0.533\n",
            "ep: 55, taked: 0.011, train_loss: 2.072, train_acc: 0.629, test_loss: 2.125, test_acc: 0.533\n",
            "ep: 56, taked: 0.014, train_loss: 2.068, train_acc: 0.629, test_loss: 2.121, test_acc: 0.533\n",
            "ep: 57, taked: 0.011, train_loss: 2.063, train_acc: 0.629, test_loss: 2.116, test_acc: 0.533\n",
            "ep: 58, taked: 0.013, train_loss: 2.058, train_acc: 0.629, test_loss: 2.112, test_acc: 0.533\n",
            "ep: 59, taked: 0.011, train_loss: 2.054, train_acc: 0.643, test_loss: 2.108, test_acc: 0.533\n",
            "ep: 60, taked: 0.011, train_loss: 2.049, train_acc: 0.643, test_loss: 2.104, test_acc: 0.533\n",
            "ep: 61, taked: 0.011, train_loss: 2.045, train_acc: 0.657, test_loss: 2.100, test_acc: 0.533\n",
            "ep: 62, taked: 0.011, train_loss: 2.040, train_acc: 0.686, test_loss: 2.096, test_acc: 0.533\n",
            "ep: 63, taked: 0.012, train_loss: 2.035, train_acc: 0.700, test_loss: 2.092, test_acc: 0.533\n",
            "ep: 64, taked: 0.012, train_loss: 2.031, train_acc: 0.700, test_loss: 2.088, test_acc: 0.533\n",
            "ep: 65, taked: 0.011, train_loss: 2.026, train_acc: 0.714, test_loss: 2.084, test_acc: 0.533\n",
            "ep: 66, taked: 0.011, train_loss: 2.022, train_acc: 0.729, test_loss: 2.080, test_acc: 0.533\n",
            "ep: 67, taked: 0.011, train_loss: 2.017, train_acc: 0.729, test_loss: 2.076, test_acc: 0.533\n",
            "ep: 68, taked: 0.015, train_loss: 2.013, train_acc: 0.729, test_loss: 2.072, test_acc: 0.567\n",
            "ep: 69, taked: 0.015, train_loss: 2.008, train_acc: 0.729, test_loss: 2.068, test_acc: 0.567\n",
            "ep: 70, taked: 0.011, train_loss: 2.003, train_acc: 0.729, test_loss: 2.064, test_acc: 0.567\n",
            "ep: 71, taked: 0.011, train_loss: 1.999, train_acc: 0.729, test_loss: 2.060, test_acc: 0.600\n",
            "ep: 72, taked: 0.011, train_loss: 1.994, train_acc: 0.743, test_loss: 2.056, test_acc: 0.600\n",
            "ep: 73, taked: 0.011, train_loss: 1.990, train_acc: 0.743, test_loss: 2.052, test_acc: 0.633\n",
            "ep: 74, taked: 0.013, train_loss: 1.985, train_acc: 0.743, test_loss: 2.048, test_acc: 0.633\n",
            "ep: 75, taked: 0.014, train_loss: 1.981, train_acc: 0.743, test_loss: 2.044, test_acc: 0.633\n",
            "ep: 76, taked: 0.013, train_loss: 1.976, train_acc: 0.743, test_loss: 2.040, test_acc: 0.667\n",
            "ep: 77, taked: 0.021, train_loss: 1.972, train_acc: 0.743, test_loss: 2.036, test_acc: 0.667\n",
            "ep: 78, taked: 0.022, train_loss: 1.967, train_acc: 0.743, test_loss: 2.032, test_acc: 0.667\n",
            "ep: 79, taked: 0.015, train_loss: 1.963, train_acc: 0.743, test_loss: 2.028, test_acc: 0.667\n",
            "ep: 80, taked: 0.010, train_loss: 1.958, train_acc: 0.743, test_loss: 2.024, test_acc: 0.667\n",
            "ep: 81, taked: 0.011, train_loss: 1.954, train_acc: 0.743, test_loss: 2.020, test_acc: 0.667\n",
            "ep: 82, taked: 0.010, train_loss: 1.949, train_acc: 0.743, test_loss: 2.016, test_acc: 0.667\n",
            "ep: 83, taked: 0.011, train_loss: 1.945, train_acc: 0.757, test_loss: 2.012, test_acc: 0.700\n",
            "ep: 84, taked: 0.011, train_loss: 1.940, train_acc: 0.757, test_loss: 2.008, test_acc: 0.700\n",
            "ep: 85, taked: 0.015, train_loss: 1.936, train_acc: 0.757, test_loss: 2.004, test_acc: 0.700\n",
            "ep: 86, taked: 0.011, train_loss: 1.931, train_acc: 0.757, test_loss: 2.001, test_acc: 0.700\n",
            "ep: 87, taked: 0.013, train_loss: 1.927, train_acc: 0.757, test_loss: 1.997, test_acc: 0.700\n",
            "ep: 88, taked: 0.010, train_loss: 1.922, train_acc: 0.771, test_loss: 1.993, test_acc: 0.700\n",
            "ep: 89, taked: 0.011, train_loss: 1.918, train_acc: 0.771, test_loss: 1.989, test_acc: 0.700\n",
            "ep: 90, taked: 0.010, train_loss: 1.913, train_acc: 0.786, test_loss: 1.985, test_acc: 0.700\n",
            "ep: 91, taked: 0.010, train_loss: 1.909, train_acc: 0.786, test_loss: 1.981, test_acc: 0.700\n",
            "ep: 92, taked: 0.010, train_loss: 1.905, train_acc: 0.800, test_loss: 1.977, test_acc: 0.700\n",
            "ep: 93, taked: 0.010, train_loss: 1.900, train_acc: 0.800, test_loss: 1.973, test_acc: 0.700\n",
            "ep: 94, taked: 0.011, train_loss: 1.896, train_acc: 0.800, test_loss: 1.969, test_acc: 0.700\n",
            "ep: 95, taked: 0.010, train_loss: 1.891, train_acc: 0.800, test_loss: 1.965, test_acc: 0.700\n",
            "ep: 96, taked: 0.010, train_loss: 1.887, train_acc: 0.800, test_loss: 1.961, test_acc: 0.700\n",
            "ep: 97, taked: 0.010, train_loss: 1.882, train_acc: 0.800, test_loss: 1.958, test_acc: 0.700\n",
            "ep: 98, taked: 0.010, train_loss: 1.878, train_acc: 0.800, test_loss: 1.954, test_acc: 0.700\n",
            "ep: 99, taked: 0.012, train_loss: 1.874, train_acc: 0.800, test_loss: 1.950, test_acc: 0.700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## При увеличении кол-ва эпох до 100 точность предсказаний RNN увеличилась до 70%, что всё равно является низкой величиной. Попробуем изменить метод оптимизации с SGD на Adam. Остальные параметры без изменений."
      ],
      "metadata": {
        "id": "84mmDCaL75g5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "jmJ1ohN8ARRy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "K4z9rUqO8iry"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOXNqRcy8qiO",
        "outputId": "58c33f4f-a00f-4f95-d665-3b3388f2e3d2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 0, taked: 0.024, train_loss: 2.268, train_acc: 0.143, test_loss: 2.187, test_acc: 0.333\n",
            "ep: 1, taked: 0.012, train_loss: 2.048, train_acc: 0.571, test_loss: 2.049, test_acc: 0.600\n",
            "ep: 2, taked: 0.012, train_loss: 1.853, train_acc: 0.886, test_loss: 1.918, test_acc: 0.900\n",
            "ep: 3, taked: 0.013, train_loss: 1.667, train_acc: 0.957, test_loss: 1.792, test_acc: 0.900\n",
            "ep: 4, taked: 0.013, train_loss: 1.487, train_acc: 0.986, test_loss: 1.672, test_acc: 0.933\n",
            "ep: 5, taked: 0.013, train_loss: 1.314, train_acc: 0.971, test_loss: 1.558, test_acc: 0.933\n",
            "ep: 6, taked: 0.014, train_loss: 1.150, train_acc: 0.971, test_loss: 1.453, test_acc: 0.867\n",
            "ep: 7, taked: 0.013, train_loss: 0.999, train_acc: 0.971, test_loss: 1.357, test_acc: 0.867\n",
            "ep: 8, taked: 0.013, train_loss: 0.864, train_acc: 0.971, test_loss: 1.270, test_acc: 0.767\n",
            "ep: 9, taked: 0.013, train_loss: 0.746, train_acc: 0.971, test_loss: 1.190, test_acc: 0.733\n",
            "ep: 10, taked: 0.014, train_loss: 0.643, train_acc: 0.986, test_loss: 1.118, test_acc: 0.733\n",
            "ep: 11, taked: 0.016, train_loss: 0.552, train_acc: 0.986, test_loss: 1.052, test_acc: 0.767\n",
            "ep: 12, taked: 0.013, train_loss: 0.473, train_acc: 0.986, test_loss: 0.996, test_acc: 0.767\n",
            "ep: 13, taked: 0.013, train_loss: 0.407, train_acc: 0.986, test_loss: 0.948, test_acc: 0.767\n",
            "ep: 14, taked: 0.013, train_loss: 0.351, train_acc: 0.986, test_loss: 0.907, test_acc: 0.800\n",
            "ep: 15, taked: 0.017, train_loss: 0.303, train_acc: 0.986, test_loss: 0.872, test_acc: 0.800\n",
            "ep: 16, taked: 0.022, train_loss: 0.264, train_acc: 0.986, test_loss: 0.841, test_acc: 0.767\n",
            "ep: 17, taked: 0.016, train_loss: 0.230, train_acc: 0.986, test_loss: 0.814, test_acc: 0.767\n",
            "ep: 18, taked: 0.012, train_loss: 0.202, train_acc: 0.986, test_loss: 0.791, test_acc: 0.767\n",
            "ep: 19, taked: 0.013, train_loss: 0.178, train_acc: 0.986, test_loss: 0.770, test_acc: 0.800\n",
            "ep: 20, taked: 0.013, train_loss: 0.158, train_acc: 0.986, test_loss: 0.753, test_acc: 0.800\n",
            "ep: 21, taked: 0.013, train_loss: 0.141, train_acc: 1.000, test_loss: 0.737, test_acc: 0.800\n",
            "ep: 22, taked: 0.014, train_loss: 0.126, train_acc: 1.000, test_loss: 0.722, test_acc: 0.800\n",
            "ep: 23, taked: 0.013, train_loss: 0.113, train_acc: 1.000, test_loss: 0.709, test_acc: 0.800\n",
            "ep: 24, taked: 0.014, train_loss: 0.103, train_acc: 1.000, test_loss: 0.696, test_acc: 0.800\n",
            "ep: 25, taked: 0.013, train_loss: 0.093, train_acc: 1.000, test_loss: 0.684, test_acc: 0.800\n",
            "ep: 26, taked: 0.013, train_loss: 0.085, train_acc: 1.000, test_loss: 0.673, test_acc: 0.800\n",
            "ep: 27, taked: 0.013, train_loss: 0.078, train_acc: 1.000, test_loss: 0.663, test_acc: 0.800\n",
            "ep: 28, taked: 0.014, train_loss: 0.072, train_acc: 1.000, test_loss: 0.653, test_acc: 0.833\n",
            "ep: 29, taked: 0.015, train_loss: 0.067, train_acc: 1.000, test_loss: 0.644, test_acc: 0.833\n",
            "ep: 30, taked: 0.016, train_loss: 0.062, train_acc: 1.000, test_loss: 0.636, test_acc: 0.833\n",
            "ep: 31, taked: 0.013, train_loss: 0.058, train_acc: 1.000, test_loss: 0.629, test_acc: 0.833\n",
            "ep: 32, taked: 0.013, train_loss: 0.054, train_acc: 1.000, test_loss: 0.622, test_acc: 0.833\n",
            "ep: 33, taked: 0.013, train_loss: 0.050, train_acc: 1.000, test_loss: 0.616, test_acc: 0.833\n",
            "ep: 34, taked: 0.013, train_loss: 0.047, train_acc: 1.000, test_loss: 0.610, test_acc: 0.833\n",
            "ep: 35, taked: 0.017, train_loss: 0.045, train_acc: 1.000, test_loss: 0.605, test_acc: 0.833\n",
            "ep: 36, taked: 0.015, train_loss: 0.042, train_acc: 1.000, test_loss: 0.599, test_acc: 0.833\n",
            "ep: 37, taked: 0.013, train_loss: 0.040, train_acc: 1.000, test_loss: 0.595, test_acc: 0.833\n",
            "ep: 38, taked: 0.013, train_loss: 0.038, train_acc: 1.000, test_loss: 0.590, test_acc: 0.833\n",
            "ep: 39, taked: 0.013, train_loss: 0.036, train_acc: 1.000, test_loss: 0.586, test_acc: 0.833\n",
            "ep: 40, taked: 0.014, train_loss: 0.034, train_acc: 1.000, test_loss: 0.582, test_acc: 0.833\n",
            "ep: 41, taked: 0.015, train_loss: 0.032, train_acc: 1.000, test_loss: 0.578, test_acc: 0.833\n",
            "ep: 42, taked: 0.013, train_loss: 0.031, train_acc: 1.000, test_loss: 0.574, test_acc: 0.833\n",
            "ep: 43, taked: 0.013, train_loss: 0.029, train_acc: 1.000, test_loss: 0.570, test_acc: 0.833\n",
            "ep: 44, taked: 0.015, train_loss: 0.028, train_acc: 1.000, test_loss: 0.567, test_acc: 0.833\n",
            "ep: 45, taked: 0.020, train_loss: 0.027, train_acc: 1.000, test_loss: 0.564, test_acc: 0.833\n",
            "ep: 46, taked: 0.013, train_loss: 0.026, train_acc: 1.000, test_loss: 0.561, test_acc: 0.833\n",
            "ep: 47, taked: 0.013, train_loss: 0.025, train_acc: 1.000, test_loss: 0.558, test_acc: 0.833\n",
            "ep: 48, taked: 0.013, train_loss: 0.024, train_acc: 1.000, test_loss: 0.555, test_acc: 0.833\n",
            "ep: 49, taked: 0.012, train_loss: 0.023, train_acc: 1.000, test_loss: 0.552, test_acc: 0.833\n",
            "ep: 50, taked: 0.013, train_loss: 0.022, train_acc: 1.000, test_loss: 0.549, test_acc: 0.833\n",
            "ep: 51, taked: 0.013, train_loss: 0.021, train_acc: 1.000, test_loss: 0.547, test_acc: 0.833\n",
            "ep: 52, taked: 0.013, train_loss: 0.020, train_acc: 1.000, test_loss: 0.544, test_acc: 0.833\n",
            "ep: 53, taked: 0.013, train_loss: 0.019, train_acc: 1.000, test_loss: 0.542, test_acc: 0.833\n",
            "ep: 54, taked: 0.017, train_loss: 0.019, train_acc: 1.000, test_loss: 0.540, test_acc: 0.833\n",
            "ep: 55, taked: 0.015, train_loss: 0.018, train_acc: 1.000, test_loss: 0.538, test_acc: 0.833\n",
            "ep: 56, taked: 0.017, train_loss: 0.017, train_acc: 1.000, test_loss: 0.536, test_acc: 0.833\n",
            "ep: 57, taked: 0.022, train_loss: 0.017, train_acc: 1.000, test_loss: 0.534, test_acc: 0.833\n",
            "ep: 58, taked: 0.018, train_loss: 0.016, train_acc: 1.000, test_loss: 0.532, test_acc: 0.833\n",
            "ep: 59, taked: 0.014, train_loss: 0.016, train_acc: 1.000, test_loss: 0.530, test_acc: 0.833\n",
            "ep: 60, taked: 0.012, train_loss: 0.015, train_acc: 1.000, test_loss: 0.528, test_acc: 0.833\n",
            "ep: 61, taked: 0.012, train_loss: 0.015, train_acc: 1.000, test_loss: 0.526, test_acc: 0.833\n",
            "ep: 62, taked: 0.013, train_loss: 0.014, train_acc: 1.000, test_loss: 0.524, test_acc: 0.833\n",
            "ep: 63, taked: 0.015, train_loss: 0.014, train_acc: 1.000, test_loss: 0.523, test_acc: 0.833\n",
            "ep: 64, taked: 0.012, train_loss: 0.014, train_acc: 1.000, test_loss: 0.521, test_acc: 0.833\n",
            "ep: 65, taked: 0.013, train_loss: 0.013, train_acc: 1.000, test_loss: 0.520, test_acc: 0.833\n",
            "ep: 66, taked: 0.013, train_loss: 0.013, train_acc: 1.000, test_loss: 0.518, test_acc: 0.833\n",
            "ep: 67, taked: 0.013, train_loss: 0.012, train_acc: 1.000, test_loss: 0.517, test_acc: 0.833\n",
            "ep: 68, taked: 0.013, train_loss: 0.012, train_acc: 1.000, test_loss: 0.515, test_acc: 0.833\n",
            "ep: 69, taked: 0.013, train_loss: 0.012, train_acc: 1.000, test_loss: 0.514, test_acc: 0.833\n",
            "ep: 70, taked: 0.013, train_loss: 0.011, train_acc: 1.000, test_loss: 0.513, test_acc: 0.833\n",
            "ep: 71, taked: 0.013, train_loss: 0.011, train_acc: 1.000, test_loss: 0.511, test_acc: 0.833\n",
            "ep: 72, taked: 0.013, train_loss: 0.011, train_acc: 1.000, test_loss: 0.510, test_acc: 0.833\n",
            "ep: 73, taked: 0.018, train_loss: 0.011, train_acc: 1.000, test_loss: 0.509, test_acc: 0.833\n",
            "ep: 74, taked: 0.017, train_loss: 0.010, train_acc: 1.000, test_loss: 0.508, test_acc: 0.833\n",
            "ep: 75, taked: 0.012, train_loss: 0.010, train_acc: 1.000, test_loss: 0.507, test_acc: 0.833\n",
            "ep: 76, taked: 0.012, train_loss: 0.010, train_acc: 1.000, test_loss: 0.505, test_acc: 0.833\n",
            "ep: 77, taked: 0.012, train_loss: 0.010, train_acc: 1.000, test_loss: 0.504, test_acc: 0.833\n",
            "ep: 78, taked: 0.012, train_loss: 0.009, train_acc: 1.000, test_loss: 0.503, test_acc: 0.833\n",
            "ep: 79, taked: 0.013, train_loss: 0.009, train_acc: 1.000, test_loss: 0.502, test_acc: 0.833\n",
            "ep: 80, taked: 0.013, train_loss: 0.009, train_acc: 1.000, test_loss: 0.501, test_acc: 0.833\n",
            "ep: 81, taked: 0.015, train_loss: 0.009, train_acc: 1.000, test_loss: 0.500, test_acc: 0.833\n",
            "ep: 82, taked: 0.015, train_loss: 0.009, train_acc: 1.000, test_loss: 0.499, test_acc: 0.833\n",
            "ep: 83, taked: 0.012, train_loss: 0.008, train_acc: 1.000, test_loss: 0.498, test_acc: 0.833\n",
            "ep: 84, taked: 0.012, train_loss: 0.008, train_acc: 1.000, test_loss: 0.498, test_acc: 0.833\n",
            "ep: 85, taked: 0.013, train_loss: 0.008, train_acc: 1.000, test_loss: 0.497, test_acc: 0.833\n",
            "ep: 86, taked: 0.012, train_loss: 0.008, train_acc: 1.000, test_loss: 0.496, test_acc: 0.833\n",
            "ep: 87, taked: 0.012, train_loss: 0.008, train_acc: 1.000, test_loss: 0.495, test_acc: 0.833\n",
            "ep: 88, taked: 0.015, train_loss: 0.007, train_acc: 1.000, test_loss: 0.494, test_acc: 0.833\n",
            "ep: 89, taked: 0.020, train_loss: 0.007, train_acc: 1.000, test_loss: 0.493, test_acc: 0.833\n",
            "ep: 90, taked: 0.015, train_loss: 0.007, train_acc: 1.000, test_loss: 0.493, test_acc: 0.833\n",
            "ep: 91, taked: 0.012, train_loss: 0.007, train_acc: 1.000, test_loss: 0.492, test_acc: 0.833\n",
            "ep: 92, taked: 0.017, train_loss: 0.007, train_acc: 1.000, test_loss: 0.491, test_acc: 0.833\n",
            "ep: 93, taked: 0.012, train_loss: 0.007, train_acc: 1.000, test_loss: 0.491, test_acc: 0.833\n",
            "ep: 94, taked: 0.012, train_loss: 0.007, train_acc: 1.000, test_loss: 0.490, test_acc: 0.833\n",
            "ep: 95, taked: 0.013, train_loss: 0.006, train_acc: 1.000, test_loss: 0.489, test_acc: 0.833\n",
            "ep: 96, taked: 0.013, train_loss: 0.006, train_acc: 1.000, test_loss: 0.488, test_acc: 0.833\n",
            "ep: 97, taked: 0.013, train_loss: 0.006, train_acc: 1.000, test_loss: 0.488, test_acc: 0.833\n",
            "ep: 98, taked: 0.013, train_loss: 0.006, train_acc: 1.000, test_loss: 0.487, test_acc: 0.833\n",
            "ep: 99, taked: 0.013, train_loss: 0.006, train_acc: 1.000, test_loss: 0.487, test_acc: 0.833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Мы видим, что точность предсказаний 93% была достигнута ячейкой RNN уже на 5-ой эпохе, затем качество упало до 83%??? Но в целом, оптимизатор Adam справился с задачей гораздо лучше, чем SGD.\n",
        "\n",
        "## Попробуем теперь при этих же исходных параметрах сделать предсказание с помощью ячейки LSTM."
      ],
      "metadata": {
        "id": "Ovxsf6xkAg4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "0dVrkoaLDTY4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, rnnClass, dictionary_size, embedding_size, num_hiddens, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.embedding = nn.Embedding(dictionary_size, embedding_size)\n",
        "        self.hidden = rnnClass(embedding_size, num_hiddens, batch_first=True)\n",
        "        self.output = nn.Linear(num_hiddens, num_classes)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        out = self.embedding(X)\n",
        "        s, state = self.hidden(out)\n",
        "        # predictions = self.output(state[0].squeeze())\n",
        "        predictions = self.output(s)\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "aZnfPiqDC2ad"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# для сравнения возьмем те же параметры ячейки LSTM, что и в RNN\n",
        "model = NeuralNetwork(nn.LSTM, 10, 20, 128, 10) "
      ],
      "metadata": {
        "id": "8z-OpKbUDfV-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "cOA6BqLOFOYo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIv-KeimD0Va",
        "outputId": "a5bd00aa-49c7-4d6a-acd9-ee853b76f5ed"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 0, taked: 0.037, train_loss: 2.290, train_acc: 0.171, test_loss: 2.249, test_acc: 0.367\n",
            "ep: 1, taked: 0.027, train_loss: 2.227, train_acc: 0.314, test_loss: 2.199, test_acc: 0.400\n",
            "ep: 2, taked: 0.026, train_loss: 2.166, train_acc: 0.443, test_loss: 2.148, test_acc: 0.433\n",
            "ep: 3, taked: 0.033, train_loss: 2.100, train_acc: 0.629, test_loss: 2.093, test_acc: 0.433\n",
            "ep: 4, taked: 0.025, train_loss: 2.025, train_acc: 0.643, test_loss: 2.033, test_acc: 0.433\n",
            "ep: 5, taked: 0.025, train_loss: 1.938, train_acc: 0.643, test_loss: 1.970, test_acc: 0.467\n",
            "ep: 6, taked: 0.025, train_loss: 1.837, train_acc: 0.629, test_loss: 1.918, test_acc: 0.367\n",
            "ep: 7, taked: 0.025, train_loss: 1.727, train_acc: 0.600, test_loss: 1.873, test_acc: 0.367\n",
            "ep: 8, taked: 0.031, train_loss: 1.604, train_acc: 0.686, test_loss: 1.788, test_acc: 0.467\n",
            "ep: 9, taked: 0.025, train_loss: 1.464, train_acc: 0.729, test_loss: 1.683, test_acc: 0.567\n",
            "ep: 10, taked: 0.024, train_loss: 1.317, train_acc: 0.786, test_loss: 1.603, test_acc: 0.667\n",
            "ep: 11, taked: 0.024, train_loss: 1.170, train_acc: 0.814, test_loss: 1.546, test_acc: 0.700\n",
            "ep: 12, taked: 0.026, train_loss: 1.032, train_acc: 0.886, test_loss: 1.466, test_acc: 0.733\n",
            "ep: 13, taked: 0.024, train_loss: 0.905, train_acc: 0.943, test_loss: 1.387, test_acc: 0.767\n",
            "ep: 14, taked: 0.025, train_loss: 0.792, train_acc: 0.929, test_loss: 1.316, test_acc: 0.767\n",
            "ep: 15, taked: 0.024, train_loss: 0.690, train_acc: 0.929, test_loss: 1.226, test_acc: 0.767\n",
            "ep: 16, taked: 0.027, train_loss: 0.601, train_acc: 0.943, test_loss: 1.148, test_acc: 0.767\n",
            "ep: 17, taked: 0.025, train_loss: 0.523, train_acc: 0.943, test_loss: 1.062, test_acc: 0.767\n",
            "ep: 18, taked: 0.026, train_loss: 0.455, train_acc: 0.971, test_loss: 0.988, test_acc: 0.800\n",
            "ep: 19, taked: 0.023, train_loss: 0.397, train_acc: 0.986, test_loss: 0.924, test_acc: 0.800\n",
            "ep: 20, taked: 0.032, train_loss: 0.346, train_acc: 1.000, test_loss: 0.868, test_acc: 0.800\n",
            "ep: 21, taked: 0.025, train_loss: 0.303, train_acc: 1.000, test_loss: 0.819, test_acc: 0.800\n",
            "ep: 22, taked: 0.027, train_loss: 0.267, train_acc: 1.000, test_loss: 0.775, test_acc: 0.833\n",
            "ep: 23, taked: 0.024, train_loss: 0.235, train_acc: 1.000, test_loss: 0.738, test_acc: 0.833\n",
            "ep: 24, taked: 0.030, train_loss: 0.209, train_acc: 1.000, test_loss: 0.701, test_acc: 0.867\n",
            "ep: 25, taked: 0.025, train_loss: 0.186, train_acc: 1.000, test_loss: 0.668, test_acc: 0.867\n",
            "ep: 26, taked: 0.024, train_loss: 0.167, train_acc: 1.000, test_loss: 0.636, test_acc: 0.867\n",
            "ep: 27, taked: 0.024, train_loss: 0.150, train_acc: 1.000, test_loss: 0.606, test_acc: 0.867\n",
            "ep: 28, taked: 0.026, train_loss: 0.136, train_acc: 1.000, test_loss: 0.579, test_acc: 0.867\n",
            "ep: 29, taked: 0.029, train_loss: 0.124, train_acc: 1.000, test_loss: 0.554, test_acc: 0.867\n",
            "ep: 30, taked: 0.025, train_loss: 0.113, train_acc: 1.000, test_loss: 0.532, test_acc: 0.867\n",
            "ep: 31, taked: 0.025, train_loss: 0.104, train_acc: 1.000, test_loss: 0.511, test_acc: 0.867\n",
            "ep: 32, taked: 0.031, train_loss: 0.096, train_acc: 1.000, test_loss: 0.493, test_acc: 0.900\n",
            "ep: 33, taked: 0.029, train_loss: 0.089, train_acc: 1.000, test_loss: 0.476, test_acc: 0.900\n",
            "ep: 34, taked: 0.029, train_loss: 0.082, train_acc: 1.000, test_loss: 0.461, test_acc: 0.900\n",
            "ep: 35, taked: 0.025, train_loss: 0.076, train_acc: 1.000, test_loss: 0.447, test_acc: 0.900\n",
            "ep: 36, taked: 0.025, train_loss: 0.071, train_acc: 1.000, test_loss: 0.434, test_acc: 0.900\n",
            "ep: 37, taked: 0.025, train_loss: 0.067, train_acc: 1.000, test_loss: 0.423, test_acc: 0.900\n",
            "ep: 38, taked: 0.025, train_loss: 0.063, train_acc: 1.000, test_loss: 0.412, test_acc: 0.900\n",
            "ep: 39, taked: 0.026, train_loss: 0.059, train_acc: 1.000, test_loss: 0.402, test_acc: 0.900\n",
            "ep: 40, taked: 0.030, train_loss: 0.056, train_acc: 1.000, test_loss: 0.393, test_acc: 0.900\n",
            "ep: 41, taked: 0.033, train_loss: 0.053, train_acc: 1.000, test_loss: 0.384, test_acc: 0.900\n",
            "ep: 42, taked: 0.029, train_loss: 0.050, train_acc: 1.000, test_loss: 0.376, test_acc: 0.900\n",
            "ep: 43, taked: 0.025, train_loss: 0.047, train_acc: 1.000, test_loss: 0.369, test_acc: 0.900\n",
            "ep: 44, taked: 0.028, train_loss: 0.045, train_acc: 1.000, test_loss: 0.362, test_acc: 0.900\n",
            "ep: 45, taked: 0.025, train_loss: 0.043, train_acc: 1.000, test_loss: 0.355, test_acc: 0.900\n",
            "ep: 46, taked: 0.027, train_loss: 0.041, train_acc: 1.000, test_loss: 0.349, test_acc: 0.900\n",
            "ep: 47, taked: 0.025, train_loss: 0.039, train_acc: 1.000, test_loss: 0.343, test_acc: 0.900\n",
            "ep: 48, taked: 0.029, train_loss: 0.037, train_acc: 1.000, test_loss: 0.337, test_acc: 0.900\n",
            "ep: 49, taked: 0.026, train_loss: 0.035, train_acc: 1.000, test_loss: 0.332, test_acc: 0.933\n",
            "ep: 50, taked: 0.028, train_loss: 0.034, train_acc: 1.000, test_loss: 0.327, test_acc: 0.933\n",
            "ep: 51, taked: 0.026, train_loss: 0.032, train_acc: 1.000, test_loss: 0.322, test_acc: 0.933\n",
            "ep: 52, taked: 0.025, train_loss: 0.031, train_acc: 1.000, test_loss: 0.318, test_acc: 0.933\n",
            "ep: 53, taked: 0.025, train_loss: 0.030, train_acc: 1.000, test_loss: 0.313, test_acc: 0.933\n",
            "ep: 54, taked: 0.025, train_loss: 0.028, train_acc: 1.000, test_loss: 0.309, test_acc: 0.933\n",
            "ep: 55, taked: 0.025, train_loss: 0.027, train_acc: 1.000, test_loss: 0.305, test_acc: 0.933\n",
            "ep: 56, taked: 0.032, train_loss: 0.026, train_acc: 1.000, test_loss: 0.301, test_acc: 0.933\n",
            "ep: 57, taked: 0.025, train_loss: 0.025, train_acc: 1.000, test_loss: 0.298, test_acc: 0.933\n",
            "ep: 58, taked: 0.024, train_loss: 0.024, train_acc: 1.000, test_loss: 0.294, test_acc: 0.933\n",
            "ep: 59, taked: 0.026, train_loss: 0.024, train_acc: 1.000, test_loss: 0.291, test_acc: 0.967\n",
            "ep: 60, taked: 0.024, train_loss: 0.023, train_acc: 1.000, test_loss: 0.287, test_acc: 0.967\n",
            "ep: 61, taked: 0.030, train_loss: 0.022, train_acc: 1.000, test_loss: 0.284, test_acc: 0.967\n",
            "ep: 62, taked: 0.025, train_loss: 0.021, train_acc: 1.000, test_loss: 0.281, test_acc: 0.967\n",
            "ep: 63, taked: 0.025, train_loss: 0.020, train_acc: 1.000, test_loss: 0.278, test_acc: 0.967\n",
            "ep: 64, taked: 0.029, train_loss: 0.020, train_acc: 1.000, test_loss: 0.275, test_acc: 0.967\n",
            "ep: 65, taked: 0.025, train_loss: 0.019, train_acc: 1.000, test_loss: 0.273, test_acc: 0.967\n",
            "ep: 66, taked: 0.036, train_loss: 0.019, train_acc: 1.000, test_loss: 0.270, test_acc: 0.967\n",
            "ep: 67, taked: 0.026, train_loss: 0.018, train_acc: 1.000, test_loss: 0.267, test_acc: 0.967\n",
            "ep: 68, taked: 0.025, train_loss: 0.017, train_acc: 1.000, test_loss: 0.265, test_acc: 0.967\n",
            "ep: 69, taked: 0.026, train_loss: 0.017, train_acc: 1.000, test_loss: 0.263, test_acc: 0.967\n",
            "ep: 70, taked: 0.025, train_loss: 0.016, train_acc: 1.000, test_loss: 0.260, test_acc: 0.967\n",
            "ep: 71, taked: 0.024, train_loss: 0.016, train_acc: 1.000, test_loss: 0.258, test_acc: 0.967\n",
            "ep: 72, taked: 0.028, train_loss: 0.015, train_acc: 1.000, test_loss: 0.256, test_acc: 0.967\n",
            "ep: 73, taked: 0.027, train_loss: 0.015, train_acc: 1.000, test_loss: 0.254, test_acc: 0.967\n",
            "ep: 74, taked: 0.025, train_loss: 0.015, train_acc: 1.000, test_loss: 0.252, test_acc: 0.967\n",
            "ep: 75, taked: 0.033, train_loss: 0.014, train_acc: 1.000, test_loss: 0.250, test_acc: 0.967\n",
            "ep: 76, taked: 0.026, train_loss: 0.014, train_acc: 1.000, test_loss: 0.248, test_acc: 0.967\n",
            "ep: 77, taked: 0.029, train_loss: 0.013, train_acc: 1.000, test_loss: 0.246, test_acc: 0.967\n",
            "ep: 78, taked: 0.025, train_loss: 0.013, train_acc: 1.000, test_loss: 0.244, test_acc: 0.967\n",
            "ep: 79, taked: 0.038, train_loss: 0.013, train_acc: 1.000, test_loss: 0.242, test_acc: 0.967\n",
            "ep: 80, taked: 0.036, train_loss: 0.012, train_acc: 1.000, test_loss: 0.240, test_acc: 0.967\n",
            "ep: 81, taked: 0.025, train_loss: 0.012, train_acc: 1.000, test_loss: 0.239, test_acc: 0.967\n",
            "ep: 82, taked: 0.025, train_loss: 0.012, train_acc: 1.000, test_loss: 0.237, test_acc: 0.967\n",
            "ep: 83, taked: 0.024, train_loss: 0.012, train_acc: 1.000, test_loss: 0.235, test_acc: 0.967\n",
            "ep: 84, taked: 0.026, train_loss: 0.011, train_acc: 1.000, test_loss: 0.234, test_acc: 0.967\n",
            "ep: 85, taked: 0.025, train_loss: 0.011, train_acc: 1.000, test_loss: 0.232, test_acc: 0.967\n",
            "ep: 86, taked: 0.027, train_loss: 0.011, train_acc: 1.000, test_loss: 0.231, test_acc: 0.967\n",
            "ep: 87, taked: 0.029, train_loss: 0.010, train_acc: 1.000, test_loss: 0.229, test_acc: 0.967\n",
            "ep: 88, taked: 0.025, train_loss: 0.010, train_acc: 1.000, test_loss: 0.228, test_acc: 0.967\n",
            "ep: 89, taked: 0.025, train_loss: 0.010, train_acc: 1.000, test_loss: 0.226, test_acc: 0.967\n",
            "ep: 90, taked: 0.029, train_loss: 0.010, train_acc: 1.000, test_loss: 0.225, test_acc: 0.967\n",
            "ep: 91, taked: 0.023, train_loss: 0.010, train_acc: 1.000, test_loss: 0.224, test_acc: 0.967\n",
            "ep: 92, taked: 0.023, train_loss: 0.009, train_acc: 1.000, test_loss: 0.222, test_acc: 0.967\n",
            "ep: 93, taked: 0.023, train_loss: 0.009, train_acc: 1.000, test_loss: 0.221, test_acc: 0.967\n",
            "ep: 94, taked: 0.024, train_loss: 0.009, train_acc: 1.000, test_loss: 0.220, test_acc: 1.000\n",
            "ep: 95, taked: 0.023, train_loss: 0.009, train_acc: 1.000, test_loss: 0.218, test_acc: 1.000\n",
            "ep: 96, taked: 0.027, train_loss: 0.009, train_acc: 1.000, test_loss: 0.217, test_acc: 1.000\n",
            "ep: 97, taked: 0.027, train_loss: 0.008, train_acc: 1.000, test_loss: 0.216, test_acc: 1.000\n",
            "ep: 98, taked: 0.028, train_loss: 0.008, train_acc: 1.000, test_loss: 0.215, test_acc: 1.000\n",
            "ep: 99, taked: 0.024, train_loss: 0.008, train_acc: 1.000, test_loss: 0.214, test_acc: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Мы видим, что LSTM достигла качества предсказаний на тестовой выборке в 100%. Качество выше 90% достигнуто на 33-ей эпохе (у RNN 93% на 5-ой эпохе).\n",
        "\n",
        "## Попробуем теперь GRU."
      ],
      "metadata": {
        "id": "fYEc4gDlHMwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# для сравнения возьмем те же параметры ячейки GRU, что и в RNN & LSTM\n",
        "model = NeuralNetwork(nn.GRU, 10, 20, 128, 10) "
      ],
      "metadata": {
        "id": "Cz5BCnTCGf7l"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "rXI-a0hPJRN3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gciTZR6gJUuv",
        "outputId": "e147849a-d183-448a-9c52-516268eba227"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 0, taked: 0.036, train_loss: 2.276, train_acc: 0.129, test_loss: 2.214, test_acc: 0.300\n",
            "ep: 1, taked: 0.027, train_loss: 2.170, train_acc: 0.414, test_loss: 2.124, test_acc: 0.567\n",
            "ep: 2, taked: 0.027, train_loss: 2.070, train_acc: 0.643, test_loss: 2.034, test_acc: 0.633\n",
            "ep: 3, taked: 0.030, train_loss: 1.968, train_acc: 0.700, test_loss: 1.943, test_acc: 0.600\n",
            "ep: 4, taked: 0.024, train_loss: 1.862, train_acc: 0.686, test_loss: 1.849, test_acc: 0.600\n",
            "ep: 5, taked: 0.025, train_loss: 1.749, train_acc: 0.686, test_loss: 1.754, test_acc: 0.600\n",
            "ep: 6, taked: 0.025, train_loss: 1.627, train_acc: 0.686, test_loss: 1.659, test_acc: 0.633\n",
            "ep: 7, taked: 0.026, train_loss: 1.497, train_acc: 0.700, test_loss: 1.565, test_acc: 0.633\n",
            "ep: 8, taked: 0.032, train_loss: 1.361, train_acc: 0.729, test_loss: 1.467, test_acc: 0.633\n",
            "ep: 9, taked: 0.028, train_loss: 1.219, train_acc: 0.814, test_loss: 1.359, test_acc: 0.667\n",
            "ep: 10, taked: 0.027, train_loss: 1.077, train_acc: 0.829, test_loss: 1.246, test_acc: 0.700\n",
            "ep: 11, taked: 0.035, train_loss: 0.942, train_acc: 0.871, test_loss: 1.138, test_acc: 0.700\n",
            "ep: 12, taked: 0.027, train_loss: 0.818, train_acc: 0.929, test_loss: 1.040, test_acc: 0.767\n",
            "ep: 13, taked: 0.027, train_loss: 0.705, train_acc: 0.957, test_loss: 0.948, test_acc: 0.800\n",
            "ep: 14, taked: 0.025, train_loss: 0.605, train_acc: 0.971, test_loss: 0.861, test_acc: 0.900\n",
            "ep: 15, taked: 0.025, train_loss: 0.517, train_acc: 0.971, test_loss: 0.783, test_acc: 0.933\n",
            "ep: 16, taked: 0.034, train_loss: 0.440, train_acc: 0.986, test_loss: 0.716, test_acc: 0.933\n",
            "ep: 17, taked: 0.025, train_loss: 0.375, train_acc: 0.986, test_loss: 0.659, test_acc: 0.967\n",
            "ep: 18, taked: 0.025, train_loss: 0.320, train_acc: 0.986, test_loss: 0.611, test_acc: 0.967\n",
            "ep: 19, taked: 0.024, train_loss: 0.273, train_acc: 0.986, test_loss: 0.571, test_acc: 0.967\n",
            "ep: 20, taked: 0.025, train_loss: 0.235, train_acc: 0.986, test_loss: 0.539, test_acc: 0.967\n",
            "ep: 21, taked: 0.025, train_loss: 0.203, train_acc: 0.986, test_loss: 0.513, test_acc: 0.967\n",
            "ep: 22, taked: 0.025, train_loss: 0.177, train_acc: 0.986, test_loss: 0.491, test_acc: 0.967\n",
            "ep: 23, taked: 0.027, train_loss: 0.155, train_acc: 0.986, test_loss: 0.473, test_acc: 0.967\n",
            "ep: 24, taked: 0.032, train_loss: 0.136, train_acc: 0.986, test_loss: 0.457, test_acc: 0.967\n",
            "ep: 25, taked: 0.025, train_loss: 0.121, train_acc: 1.000, test_loss: 0.444, test_acc: 0.967\n",
            "ep: 26, taked: 0.031, train_loss: 0.108, train_acc: 1.000, test_loss: 0.432, test_acc: 0.967\n",
            "ep: 27, taked: 0.029, train_loss: 0.096, train_acc: 1.000, test_loss: 0.422, test_acc: 0.967\n",
            "ep: 28, taked: 0.024, train_loss: 0.087, train_acc: 1.000, test_loss: 0.413, test_acc: 0.967\n",
            "ep: 29, taked: 0.028, train_loss: 0.079, train_acc: 1.000, test_loss: 0.406, test_acc: 0.967\n",
            "ep: 30, taked: 0.025, train_loss: 0.072, train_acc: 1.000, test_loss: 0.399, test_acc: 0.933\n",
            "ep: 31, taked: 0.026, train_loss: 0.066, train_acc: 1.000, test_loss: 0.393, test_acc: 0.933\n",
            "ep: 32, taked: 0.030, train_loss: 0.060, train_acc: 1.000, test_loss: 0.387, test_acc: 0.933\n",
            "ep: 33, taked: 0.024, train_loss: 0.056, train_acc: 1.000, test_loss: 0.382, test_acc: 0.933\n",
            "ep: 34, taked: 0.025, train_loss: 0.052, train_acc: 1.000, test_loss: 0.377, test_acc: 0.933\n",
            "ep: 35, taked: 0.025, train_loss: 0.048, train_acc: 1.000, test_loss: 0.373, test_acc: 0.933\n",
            "ep: 36, taked: 0.026, train_loss: 0.045, train_acc: 1.000, test_loss: 0.369, test_acc: 0.933\n",
            "ep: 37, taked: 0.027, train_loss: 0.042, train_acc: 1.000, test_loss: 0.365, test_acc: 0.933\n",
            "ep: 38, taked: 0.026, train_loss: 0.039, train_acc: 1.000, test_loss: 0.361, test_acc: 0.933\n",
            "ep: 39, taked: 0.026, train_loss: 0.037, train_acc: 1.000, test_loss: 0.358, test_acc: 0.933\n",
            "ep: 40, taked: 0.033, train_loss: 0.035, train_acc: 1.000, test_loss: 0.355, test_acc: 0.933\n",
            "ep: 41, taked: 0.030, train_loss: 0.033, train_acc: 1.000, test_loss: 0.353, test_acc: 0.933\n",
            "ep: 42, taked: 0.030, train_loss: 0.031, train_acc: 1.000, test_loss: 0.350, test_acc: 0.933\n",
            "ep: 43, taked: 0.024, train_loss: 0.029, train_acc: 1.000, test_loss: 0.348, test_acc: 0.933\n",
            "ep: 44, taked: 0.026, train_loss: 0.028, train_acc: 1.000, test_loss: 0.345, test_acc: 0.933\n",
            "ep: 45, taked: 0.028, train_loss: 0.026, train_acc: 1.000, test_loss: 0.343, test_acc: 0.933\n",
            "ep: 46, taked: 0.026, train_loss: 0.025, train_acc: 1.000, test_loss: 0.341, test_acc: 0.933\n",
            "ep: 47, taked: 0.024, train_loss: 0.024, train_acc: 1.000, test_loss: 0.339, test_acc: 0.933\n",
            "ep: 48, taked: 0.036, train_loss: 0.023, train_acc: 1.000, test_loss: 0.338, test_acc: 0.933\n",
            "ep: 49, taked: 0.025, train_loss: 0.022, train_acc: 1.000, test_loss: 0.336, test_acc: 0.933\n",
            "ep: 50, taked: 0.025, train_loss: 0.021, train_acc: 1.000, test_loss: 0.335, test_acc: 0.933\n",
            "ep: 51, taked: 0.024, train_loss: 0.020, train_acc: 1.000, test_loss: 0.333, test_acc: 0.933\n",
            "ep: 52, taked: 0.025, train_loss: 0.019, train_acc: 1.000, test_loss: 0.332, test_acc: 0.933\n",
            "ep: 53, taked: 0.026, train_loss: 0.019, train_acc: 1.000, test_loss: 0.330, test_acc: 0.933\n",
            "ep: 54, taked: 0.025, train_loss: 0.018, train_acc: 1.000, test_loss: 0.329, test_acc: 0.933\n",
            "ep: 55, taked: 0.025, train_loss: 0.017, train_acc: 1.000, test_loss: 0.328, test_acc: 0.933\n",
            "ep: 56, taked: 0.030, train_loss: 0.017, train_acc: 1.000, test_loss: 0.327, test_acc: 0.933\n",
            "ep: 57, taked: 0.026, train_loss: 0.016, train_acc: 1.000, test_loss: 0.326, test_acc: 0.933\n",
            "ep: 58, taked: 0.025, train_loss: 0.015, train_acc: 1.000, test_loss: 0.325, test_acc: 0.933\n",
            "ep: 59, taked: 0.031, train_loss: 0.015, train_acc: 1.000, test_loss: 0.324, test_acc: 0.933\n",
            "ep: 60, taked: 0.027, train_loss: 0.014, train_acc: 1.000, test_loss: 0.323, test_acc: 0.933\n",
            "ep: 61, taked: 0.026, train_loss: 0.014, train_acc: 1.000, test_loss: 0.322, test_acc: 0.933\n",
            "ep: 62, taked: 0.028, train_loss: 0.013, train_acc: 1.000, test_loss: 0.321, test_acc: 0.933\n",
            "ep: 63, taked: 0.024, train_loss: 0.013, train_acc: 1.000, test_loss: 0.321, test_acc: 0.933\n",
            "ep: 64, taked: 0.030, train_loss: 0.013, train_acc: 1.000, test_loss: 0.320, test_acc: 0.933\n",
            "ep: 65, taked: 0.023, train_loss: 0.012, train_acc: 1.000, test_loss: 0.319, test_acc: 0.933\n",
            "ep: 66, taked: 0.027, train_loss: 0.012, train_acc: 1.000, test_loss: 0.319, test_acc: 0.933\n",
            "ep: 67, taked: 0.024, train_loss: 0.011, train_acc: 1.000, test_loss: 0.318, test_acc: 0.933\n",
            "ep: 68, taked: 0.025, train_loss: 0.011, train_acc: 1.000, test_loss: 0.317, test_acc: 0.933\n",
            "ep: 69, taked: 0.026, train_loss: 0.011, train_acc: 1.000, test_loss: 0.317, test_acc: 0.933\n",
            "ep: 70, taked: 0.025, train_loss: 0.010, train_acc: 1.000, test_loss: 0.316, test_acc: 0.933\n",
            "ep: 71, taked: 0.024, train_loss: 0.010, train_acc: 1.000, test_loss: 0.316, test_acc: 0.933\n",
            "ep: 72, taked: 0.029, train_loss: 0.010, train_acc: 1.000, test_loss: 0.315, test_acc: 0.933\n",
            "ep: 73, taked: 0.025, train_loss: 0.010, train_acc: 1.000, test_loss: 0.315, test_acc: 0.933\n",
            "ep: 74, taked: 0.032, train_loss: 0.009, train_acc: 1.000, test_loss: 0.314, test_acc: 0.933\n",
            "ep: 75, taked: 0.025, train_loss: 0.009, train_acc: 1.000, test_loss: 0.314, test_acc: 0.933\n",
            "ep: 76, taked: 0.024, train_loss: 0.009, train_acc: 1.000, test_loss: 0.313, test_acc: 0.933\n",
            "ep: 77, taked: 0.025, train_loss: 0.009, train_acc: 1.000, test_loss: 0.313, test_acc: 0.933\n",
            "ep: 78, taked: 0.024, train_loss: 0.008, train_acc: 1.000, test_loss: 0.313, test_acc: 0.933\n",
            "ep: 79, taked: 0.025, train_loss: 0.008, train_acc: 1.000, test_loss: 0.312, test_acc: 0.933\n",
            "ep: 80, taked: 0.030, train_loss: 0.008, train_acc: 1.000, test_loss: 0.312, test_acc: 0.933\n",
            "ep: 81, taked: 0.025, train_loss: 0.008, train_acc: 1.000, test_loss: 0.312, test_acc: 0.933\n",
            "ep: 82, taked: 0.025, train_loss: 0.008, train_acc: 1.000, test_loss: 0.311, test_acc: 0.933\n",
            "ep: 83, taked: 0.025, train_loss: 0.008, train_acc: 1.000, test_loss: 0.311, test_acc: 0.933\n",
            "ep: 84, taked: 0.025, train_loss: 0.007, train_acc: 1.000, test_loss: 0.311, test_acc: 0.933\n",
            "ep: 85, taked: 0.026, train_loss: 0.007, train_acc: 1.000, test_loss: 0.311, test_acc: 0.933\n",
            "ep: 86, taked: 0.029, train_loss: 0.007, train_acc: 1.000, test_loss: 0.310, test_acc: 0.933\n",
            "ep: 87, taked: 0.032, train_loss: 0.007, train_acc: 1.000, test_loss: 0.310, test_acc: 0.933\n",
            "ep: 88, taked: 0.029, train_loss: 0.007, train_acc: 1.000, test_loss: 0.310, test_acc: 0.933\n",
            "ep: 89, taked: 0.036, train_loss: 0.007, train_acc: 1.000, test_loss: 0.310, test_acc: 0.933\n",
            "ep: 90, taked: 0.040, train_loss: 0.006, train_acc: 1.000, test_loss: 0.309, test_acc: 0.933\n",
            "ep: 91, taked: 0.026, train_loss: 0.006, train_acc: 1.000, test_loss: 0.309, test_acc: 0.933\n",
            "ep: 92, taked: 0.024, train_loss: 0.006, train_acc: 1.000, test_loss: 0.309, test_acc: 0.933\n",
            "ep: 93, taked: 0.026, train_loss: 0.006, train_acc: 1.000, test_loss: 0.309, test_acc: 0.933\n",
            "ep: 94, taked: 0.025, train_loss: 0.006, train_acc: 1.000, test_loss: 0.309, test_acc: 0.933\n",
            "ep: 95, taked: 0.029, train_loss: 0.006, train_acc: 1.000, test_loss: 0.308, test_acc: 0.933\n",
            "ep: 96, taked: 0.025, train_loss: 0.006, train_acc: 1.000, test_loss: 0.308, test_acc: 0.933\n",
            "ep: 97, taked: 0.025, train_loss: 0.006, train_acc: 1.000, test_loss: 0.308, test_acc: 0.933\n",
            "ep: 98, taked: 0.026, train_loss: 0.005, train_acc: 1.000, test_loss: 0.308, test_acc: 0.933\n",
            "ep: 99, taked: 0.036, train_loss: 0.005, train_acc: 1.000, test_loss: 0.308, test_acc: 0.933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Мы видим, что точность на тестовой выборке выше 90% достигнута ячейкой GRU на 15-ой эпохе - чуть медленнее, чем RNN (5 эпох), но значительно быстрее, чем LSTM (33 эпохи). \n",
        "\n",
        "## Т.е. по точности предсказаний наилучшим образом отработала LSTM (но медленнее всех). По скорости предсказаний с приемлемой точностью - RNN. При этом GRU расположилась \"посередине\".\n",
        "\n",
        "## В заключение попробуем существенно увеличить количество сэмплов (со 100 до 1000 шт.) - для проверки гипотезы, что на большом датасете RNN сможет выучить закономерности быстрее, чем на малом."
      ],
      "metadata": {
        "id": "YY6ILgJKJoiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# зададим количество сэмплов, а также инициализируем X и Y\n",
        "samples = 1000\n",
        "X = torch.zeros(samples, dtype=int)\n",
        "Y = torch.zeros(samples, dtype=int)"
      ],
      "metadata": {
        "id": "NOHWFUc-LRHk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сгенерируем X, предварительно зафиксировав генератор случайных чисел (для воспроизводимости результатов)\n",
        "random.seed(12)\n",
        "for i in range(samples):\n",
        "  X[i] = randint(0, 9)"
      ],
      "metadata": {
        "id": "g3NkjVaELUWG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# теперь на основании X сгенерируем Y\n",
        "Y[0] = X[0]\n",
        "for i in range(1, samples):\n",
        "  Y[i] = X[i] + X[0]\n",
        "  if Y[i] >= 10:\n",
        "     Y[i] -= 10"
      ],
      "metadata": {
        "id": "kmL1pKzJLhHj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)"
      ],
      "metadata": {
        "id": "FL8q9BspLmVk"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# размер батча оставим прежним\n",
        "BATCH_SIZE=20"
      ],
      "metadata": {
        "id": "2ybWPkCaLmSB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "data_train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "data_test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "vizsgDbYLweO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "\n",
        "num_epochs = 30\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
      ],
      "metadata": {
        "id": "PBmXykiIL7HL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psj1nBZlMK1T",
        "outputId": "bbd7dca4-73bd-44f0-ba28-a55657254695"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 0, taked: 0.121, train_loss: 1.783, train_acc: 0.660, test_loss: 1.224, test_acc: 0.947\n",
            "ep: 1, taked: 0.114, train_loss: 0.834, train_acc: 0.993, test_loss: 0.489, test_acc: 1.000\n",
            "ep: 2, taked: 0.110, train_loss: 0.310, train_acc: 0.999, test_loss: 0.178, test_acc: 1.000\n",
            "ep: 3, taked: 0.107, train_loss: 0.123, train_acc: 0.999, test_loss: 0.081, test_acc: 1.000\n",
            "ep: 4, taked: 0.112, train_loss: 0.065, train_acc: 0.999, test_loss: 0.047, test_acc: 1.000\n",
            "ep: 5, taked: 0.106, train_loss: 0.042, train_acc: 0.999, test_loss: 0.032, test_acc: 1.000\n",
            "ep: 6, taked: 0.120, train_loss: 0.030, train_acc: 0.999, test_loss: 0.023, test_acc: 1.000\n",
            "ep: 7, taked: 0.115, train_loss: 0.023, train_acc: 0.999, test_loss: 0.018, test_acc: 1.000\n",
            "ep: 8, taked: 0.112, train_loss: 0.018, train_acc: 0.999, test_loss: 0.014, test_acc: 1.000\n",
            "ep: 9, taked: 0.129, train_loss: 0.015, train_acc: 0.999, test_loss: 0.012, test_acc: 1.000\n",
            "ep: 10, taked: 0.118, train_loss: 0.012, train_acc: 0.999, test_loss: 0.010, test_acc: 1.000\n",
            "ep: 11, taked: 0.105, train_loss: 0.010, train_acc: 1.000, test_loss: 0.008, test_acc: 1.000\n",
            "ep: 12, taked: 0.117, train_loss: 0.008, train_acc: 1.000, test_loss: 0.007, test_acc: 1.000\n",
            "ep: 13, taked: 0.115, train_loss: 0.007, train_acc: 1.000, test_loss: 0.006, test_acc: 1.000\n",
            "ep: 14, taked: 0.111, train_loss: 0.006, train_acc: 1.000, test_loss: 0.005, test_acc: 1.000\n",
            "ep: 15, taked: 0.108, train_loss: 0.005, train_acc: 1.000, test_loss: 0.005, test_acc: 1.000\n",
            "ep: 16, taked: 0.111, train_loss: 0.004, train_acc: 1.000, test_loss: 0.004, test_acc: 1.000\n",
            "ep: 17, taked: 0.104, train_loss: 0.004, train_acc: 1.000, test_loss: 0.004, test_acc: 1.000\n",
            "ep: 18, taked: 0.113, train_loss: 0.003, train_acc: 1.000, test_loss: 0.003, test_acc: 1.000\n",
            "ep: 19, taked: 0.131, train_loss: 0.003, train_acc: 1.000, test_loss: 0.003, test_acc: 1.000\n",
            "ep: 20, taked: 0.107, train_loss: 0.003, train_acc: 1.000, test_loss: 0.003, test_acc: 1.000\n",
            "ep: 21, taked: 0.108, train_loss: 0.003, train_acc: 1.000, test_loss: 0.003, test_acc: 1.000\n",
            "ep: 22, taked: 0.111, train_loss: 0.002, train_acc: 1.000, test_loss: 0.002, test_acc: 1.000\n",
            "ep: 23, taked: 0.102, train_loss: 0.002, train_acc: 1.000, test_loss: 0.002, test_acc: 1.000\n",
            "ep: 24, taked: 0.111, train_loss: 0.002, train_acc: 1.000, test_loss: 0.002, test_acc: 1.000\n",
            "ep: 25, taked: 0.131, train_loss: 0.002, train_acc: 1.000, test_loss: 0.002, test_acc: 1.000\n",
            "ep: 26, taked: 0.119, train_loss: 0.002, train_acc: 1.000, test_loss: 0.002, test_acc: 1.000\n",
            "ep: 27, taked: 0.106, train_loss: 0.002, train_acc: 1.000, test_loss: 0.002, test_acc: 1.000\n",
            "ep: 28, taked: 0.117, train_loss: 0.001, train_acc: 1.000, test_loss: 0.001, test_acc: 1.000\n",
            "ep: 29, taked: 0.108, train_loss: 0.001, train_acc: 1.000, test_loss: 0.001, test_acc: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Гипотеза более быстрого обучения RNN на большой выборке подтвердилась - точность 100% на тестовой выборке достигнута уже на 2-ой эпохе, т.е. количество примеров для обучения (в случае несложной закономерности - такой, как в данной задаче) существенно улучшило качество и скорость предсказаний RNN."
      ],
      "metadata": {
        "id": "BIAM_ox5NWIm"
      }
    }
  ]
}